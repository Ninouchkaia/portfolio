
adapt_frequencies_pfam_to_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re


family_clan_mapping_dict = {}

with open("Pfam-A.clans.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		family = line[-2]
		clan = line[1]
		if clan != "\N" :
			family_clan_mapping_dict[family] = clan

#build dict of total swissprot counts for all PFAM domains
clan_count_dict = {}
with open("FrequenciesPfam_mapped.txt", 'rU') as file_read :
	data = file_read.readlines()
	for line in data[1:] :
		line = line.split("	")
		domain = line[1]
		if domain in family_clan_mapping_dict :
			clan = family_clan_mapping_dict[domain]
		else :
			clan = domain

		domain_count_in_swissprot = int(line[-1].replace("
",""))
		if clan not in clan_count_dict :
			clan_count_dict[clan] = domain_count_in_swissprot
		else :
			clan_count_dict[clan] = clan_count_dict[clan] + domain_count_in_swissprot





print len(clan_count_dict) #10'784

with open("FrequenciesPfam_mapped_CLANS.txt", 'a+') as file_write :
	for clan in clan_count_dict :
		file_write.write("%s	%s
" % (clan, clan_count_dict[clan])) 




stop = timeit.default_timer()
print stop - start

all_python_scripts.py 

adapt_frequencies_pfam_to_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re


family_clan_mapping_dict = {}

with open("Pfam-A.clans.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		family = line[-2]
		clan = line[1]
		if clan != "\N" :
			family_clan_mapping_dict[family] = clan

#build dict of total swissprot counts for all PFAM domains
clan_count_dict = {}
with open("FrequenciesPfam_mapped.txt", 'rU') as file_read :
	data = file_read.readlines()
	for line in data[1:] :
		line = line.split("	")
		domain = line[1]
		if domain in family_clan_mapping_dict :
			clan = family_clan_mapping_dict[domain]
		else :
			clan = domain

		domain_count_in_swissprot = int(line[-1].replace("
",""))
		if clan not in clan_count_dict :
			clan_count_dict[clan] = domain_count_in_swissprot
		else :
			clan_count_dict[clan] = clan_count_dict[clan] + domain_count_in_swissprot





print len(clan_count_dict) #10'784

with open("FrequenciesPfam_mapped_CLANS.txt", 'a+') as file_write :
	for clan in clan_count_dict :
		file_write.write("%s	%s
" % (clan, clan_count_dict[clan])) 




stop = timeit.default_timer()
print stop - start

analyze_elm_clans_mapping.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_name_list, pfam_family_list, pfam_clan_list = [], [], []

with open("elm_interaction_clans.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		elm_name_list.append(elm_name)
		pfam_family = line[1]
		pfam_family_list.append(pfam_family)
		pfam_clan = line[-1].replace("
", "")
		if pfam_clan != "\N" :
			pfam_clan_list.append(pfam_clan)


print len(elm_name_list), len(set(elm_name_list))
print len(pfam_family_list), len(set(pfam_family_list))
print len(pfam_clan_list), len(set(pfam_clan_list))






stop = timeit.default_timer()
print stop - start 

check_domain_conservation_BD_2015.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import re
from Bio import SeqIO # to parse the fasta file
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
import sys
import os
import glob
from collections import Counter, defaultdict


my_fasta = sys.argv[1]

num_homologs = int(sys.argv[2])

uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)

# uniprot_list_total = uniprot_list_total[34:56]

# for filename in glob.iglob("%s_MaxHomologs_100_queries_pfam_output/*" % my_fasta[:-6]) :
# 	uniprot_id = filename[-32:-26]






super_averaged_conservation_dict = {}
domain_name_list_total = []
for uniprot_id in uniprot_list_total :
	print uniprot_id
	filename_query = "%s_MaxHomologs_MAX%s_queries_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_query.txt" % (my_fasta[:-6], num_homologs, uniprot_id, num_homologs)
	filename_homolog = "%s_MaxHomologs_MAX%s_homologs_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_homolog.txt" % (my_fasta[:-6], num_homologs, uniprot_id, num_homologs)
	# print uniprot_id, "query"
	query_domain_dict = {}
	domain_name_list = []

	with open(filename_query, 'rU') as file_open :
		data = file_open.readlines()

		for line in data :
			if line[0] == "#" or line == "
" or "FATAL" in line:
				pass
			else :
				line = line.split()
				homolog_ref = int(line[0][7:])
				domain_name = line[6]
				domain_name_list.append(domain_name)
				domain_name_list_total.append(domain_name)
				domain_start = line[1]
				domain_end = line[2]
				if homolog_ref not in query_domain_dict :
					query_domain_dict[homolog_ref] = [(domain_name, domain_start, domain_end)]
				else :
					query_domain_dict[homolog_ref].append((domain_name, domain_start, domain_end))
		# count = sum(len(domain_names) for domain_names in query_domain_dict.itervalues())				
		# print count, "domains in query"
		domain_name_list = list(set(domain_name_list))


	# print uniprot_id, "homologs"
	homolog_domain_dict = {}
	with open(filename_homolog, 'rU') as file_open :
		data = file_open.readlines()
		for line in data :
			if line[0] == "#" or line == "
" or "FATAL" in line:
				pass
			else :
				line = line.split()
				homolog_ref = int((line[0].split("|"))[-1][7:])
				domain_name = line[6]
				domain_start = line[1]
				domain_end = line[2]
				if homolog_ref not in homolog_domain_dict :
					homolog_domain_dict[homolog_ref] = [(domain_name, domain_start, domain_end)]
				else :
					homolog_domain_dict[homolog_ref].append((domain_name, domain_start, domain_end))
	# count = sum(len(domain_names) for domain_names in homolog_domain_dict.itervalues())				
	# print count, "domains in homologs"

	
	with open("conservation_state_in_BD_%s.txt" % num_homologs, 'a+') as file_write :

		partial_conservations_dict = {}

		

		for homolog_ref in query_domain_dict :

			if homolog_ref not in homolog_domain_dict : #aucun domaine n'a été détecté dans la sequence homologue de l'alignement
				print "no Pfam domain were found in homolog of %s alignment # %s" % (uniprot_id, homolog_ref)
				for (domain_name, domain_start, domain_end) in query_domain_dict[homolog_ref] :
					file_write.write("%s	%s	%s	%s	%s	not_conserved
" % (uniprot_id, homolog_ref, domain_name, domain_start, domain_end))
			
			elif homolog_ref in homolog_domain_dict : #at least one domain was detected in the corresponding alignment	
				count_domains_in_query_dict = Counter([domain_info[0] for domain_info in query_domain_dict[homolog_ref]])
				count_domains_in_homolog_dict = Counter([domain_info[0] for domain_info in homolog_domain_dict[homolog_ref]])
				# print homolog_ref
				# print query_domain_dict[homolog_ref]
				# print count_domains_in_query_dict
				# print homolog_domain_dict[homolog_ref]
				# print count_domains_in_homolog_dict			
				for domain_name in count_domains_in_query_dict :
					if domain_name in count_domains_in_homolog_dict :
						
						if int(count_domains_in_query_dict[domain_name]) <= int(count_domains_in_homolog_dict[domain_name]) :
							for (domain_name, domain_start, domain_end) in query_domain_dict[homolog_ref] :
								file_write.write("%s	%s	%s	%s	%s	conserved
" % (uniprot_id, homolog_ref, domain_name, domain_start, domain_end))
					
						elif int(count_domains_in_query_dict[domain_name]) > int(count_domains_in_homolog_dict[domain_name]) :
							n = int(count_domains_in_query_dict[domain_name]) - int(count_domains_in_homolog_dict[domain_name])
							m = int(count_domains_in_homolog_dict[domain_name])
							file_write.write("%s	%s	%s			not_conserved
" % (uniprot_id, homolog_ref, domain_name) * n)
							file_write.write("%s	%s	%s					conserved
" % (uniprot_id, homolog_ref, domain_name) * m)




domain_name_list_total = []
with open("conservation_state_in_BD_%s.txt" % num_homologs, 'rU') as file_open :
	matched_data = file_open.readlines()
	for line in matched_data :
		line = line.split("	")
		domain_name = line[2]
		domain_name_list_total.append(domain_name)
domain_name_list_total = list(set(domain_name_list_total))

conserved, not_conserved = {}, {}
for domain_name in domain_name_list_total :
	conserved[domain_name] = 0
	not_conserved[domain_name] = 0

with open("conservation_state_in_BD_%s.txt" % num_homologs, 'rU') as file_open :
	matched_data = file_open.readlines()
	for line in matched_data :
		line = line.split("	")
		domain_name = line[2]
		conservation_state = line[-1].replace("
","")
		if conservation_state == "conserved" :
			conserved[domain_name] += 1
		elif conservation_state == "not_conserved" :
			not_conserved[domain_name] += + 1
		else : 
			print "weird conservation state", conservation_state

conservation_degree_dict = {}
with open("domain_conservation_percentages_in_BD_%s.txt" % num_homologs, 'a+') as file_write :
	for domain_name in domain_name_list_total :

				if (conserved[domain_name]+not_conserved[domain_name]) == 0 :
					print "the domain %s was NEVER found in Binding Partners" % (domain_name)
					# pass
				else :							
					percentage = float(conserved[domain_name])/float(conserved[domain_name]+not_conserved[domain_name])
					conservation_degree_dict[domain_name] = percentage
					
					file_write.write("%s	%.5f
" % (domain_name, percentage))







	


stop = timeit.default_timer()
print stop - start 

check_fasta.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

from Bio import SeqIO
import sys


ank_proteins_from_uniprot_fasta = "all-ank-20130926.fasta"
sequence_dict_from_fasta = {}
ank_from_fasta_list_total = []
with open(ank_proteins_from_uniprot_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		ank_from_fasta_list_total.append(uniprot_id)
		uniprot_seq = str(record.seq)
		sequence_dict_from_fasta[uniprot_id] = uniprot_seq

ank_proteins_from_rocio_fasta = "uniprotAnkUnique.fasta"
sequence_dict_from_rocio_fasta = {}
ank_from_rocio_fasta_list_total = []
with open(ank_proteins_from_rocio_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		ank_from_rocio_fasta_list_total.append(uniprot_id)
		uniprot_seq = str(record.seq)
		sequence_dict_from_rocio_fasta[uniprot_id] = uniprot_seq

print len(ank_from_fasta_list_total), len(ank_from_rocio_fasta_list_total)


for uniprot_id in ank_from_fasta_list_total :
	if uniprot_id not in ank_from_rocio_fasta_list_total :
		print uniprot_id
		with open("check_ank_presence_24.fasta", 'a+') as file_write :
			sequence = sequence_dict_from_fasta[uniprot_id]
			file_write.write(">sp|%s
" % uniprot_id)
			file_write.write("%s
" % sequence)



stop = timeit.default_timer()
print stop - start 

check_match_for_Zscore_positive.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math





elm_domain_mapping_dict = {}
domain_elm_mapping_dict = {}
with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_family = line[2]
		elm_domain_mapping_dict[elm_name] = pfam_family		
		domain_elm_mapping_dict[pfam_family] = elm_name

# elm_clan_mapping_dict = {}
# clan_elm_mapping_dict = {}
# with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		pfam_family = line[2]
# 		elm_domain_mapping_dict[elm_name] = pfam_family
# 		elm_domain_mapping_dict[elm_name] = pfam_family


elms_with_Zscore_positive = []
elms_with_Zscore_negative = []
elms_in_ank = []
with open("elms_counts_in_ank_proteins_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		Zscore = float(line[-2])
		if Zscore > 0 :
			elm_name = line[0]
			elms_with_Zscore_positive.append(elm_name)
		if Zscore <= 0 :
			elm_name = line[0]
			elms_with_Zscore_negative.append(elm_name)
		elm_name = line[0]
		elms_in_ank.append(elm_name)






interacting_domains_corresponding_to_elms_with_Zscore_positive = []
# with open("elms_in_ank_with_Zscore_positive.txt", 'a+') as file_write :
for elm_name in elms_with_Zscore_positive :
	if elm_name in elm_domain_mapping_dict :
		print elm_name, elm_domain_mapping_dict[elm_name]
		interacting_domains_corresponding_to_elms_with_Zscore_positive.append(elm_domain_mapping_dict[elm_name])
	else : 
		print elm_name, "doesnt have an interacting domain"
interacting_domains_corresponding_to_elms_with_Zscore_positive = list(set(interacting_domains_corresponding_to_elms_with_Zscore_positive))
print "len(interacting_domains_corresponding_to_elms_with_Zscore_positive)", len(interacting_domains_corresponding_to_elms_with_Zscore_positive)

# interacting_domains_corresponding_to_elms_with_Zscore_negative = []
# for elm_name in elms_with_Zscore_negative :
# 	if elm_name in elm_domain_mapping_dict :
# 		print elm_name, elm_domain_mapping_dict[elm_name]
# 		interacting_domains_corresponding_to_elms_with_Zscore_negative.append(elm_domain_mapping_dict[elm_name])
# 	else : 
# 		print elm_name, "doesnt have an interacting domain"
# interacting_domains_corresponding_to_elms_with_Zscore_negative = list(set(interacting_domains_corresponding_to_elms_with_Zscore_negative))
# print "len(interacting_domains_corresponding_to_elms_with_Zscore_negative)", len(interacting_domains_corresponding_to_elms_with_Zscore_negative)


# interacting_domains_corresponding_to_elms = []
# for elm_name in elms_in_ank :
# 	if elm_name in elm_domain_mapping_dict :
# 		print elm_name, elm_domain_mapping_dict[elm_name]
# 		interacting_domains_corresponding_to_elms.append(elm_domain_mapping_dict[elm_name])
# 	else : 
# 		print elm_name, "doesnt have an interacting domain"
# interacting_domains_corresponding_to_elms = list(set(interacting_domains_corresponding_to_elms))
# print "len(interacting_domains_corresponding_to_elms)", len(interacting_domains_corresponding_to_elms)





domains_with_Zscore_positive = []
with open("Pfam_domains_in_binding_partners_2038.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		Zscore = float(line[-3])
		if Zscore > 0 :
			domain_name = line[0]
			domains_with_Zscore_positive.append(domain_name)
print "len(domains_with_Zscore_positive)", len(domains_with_Zscore_positive)

# domains_with_Zscore_negative = []
# with open("Pfam_domains_in_binding_partners_2038.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		Zscore = float(line[-3])
# 		if Zscore <= 0 :
# 			domain_name = line[0]
# 			domains_with_Zscore_negative.append(domain_name)
# print "len(domains_with_Zscore_negative)", len(domains_with_Zscore_negative)


# domains_in_partners = []
# with open("Pfam_domains_in_binding_partners_2038.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		domains_in_partners.append(domain_name)
# print "len(domains_in_partners)", len(domains_in_partners)





domains_that_are_enriched_in_partners_and_match_enriched_elms_in_ank = []
for domain_name in domains_with_Zscore_positive :
	if domain_name in interacting_domains_corresponding_to_elms_with_Zscore_positive :
		domains_that_are_enriched_in_partners_and_match_enriched_elms_in_ank.append(domain_name)
		print domain_name, " : ", domain_elm_mapping_dict[domain_name]
print len(domains_that_are_enriched_in_partners_and_match_enriched_elms_in_ank)
			 
# domains_that_are_depleted_in_partners_and_match_depleted_elms_in_ank = []
# for domain_name in domains_with_Zscore_negative :
# 	if domain_name in interacting_domains_corresponding_to_elms_with_Zscore_negative :
# 		domains_that_are_depleted_in_partners_and_match_depleted_elms_in_ank.append(domain_name)
# 		print domain_name, " : ", domain_elm_mapping_dict[domain_name]
# print len(domains_that_are_depleted_in_partners_and_match_depleted_elms_in_ank)

# domains_in_partners_that_match_elms_in_ank = []
# for domain_name in domains_in_partners :
# 	if domain_name in interacting_domains_corresponding_to_elms :
# 		domains_in_partners_that_match_elms_in_ank.append(domain_name)
# 		print domain_name, " : ", domain_elm_mapping_dict[domain_name]
# print len(domains_in_partners_that_match_elms_in_ank)










stop = timeit.default_timer()
print stop - start 

check_unp_id.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

from Bio import SeqIO # to parse the fasta file
import sys
from collections import Counter


fasta_file_all_ank = sys.argv[1]
fasta_file_ank_522 = sys.argv[2]
fasta_file_BD = sys.argv[3]

unp_from_all_ank, unp_from_BD, unp_from_ank_522 = [],[],[]
with open(fasta_file_all_ank, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		unp_id = record.id[3:9]
		unp_from_all_ank.append(unp_id) 

with open(fasta_file_ank_522, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		unp_id = record.id[3:9]
		unp_from_ank_522.append(unp_id) 

with open(fasta_file_BD, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		unp_id = record.id[3:9]
		unp_from_BD.append(unp_id) 


print len(unp_from_all_ank), len(unp_from_ank_522), len(unp_from_BD)



for unp_id in unp_from_BD :
	if unp_id in unp_from_all_ank :
		print unp_id

stop = timeit.default_timer()
print stop - start 

concaten_pfam_outputs_BD_2015.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

from Bio import SeqIO # to parse the fasta file
import sys
import os



my_fasta = sys.argv[1]

num_homologs = int(sys.argv[2])

uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)


cmd = "mkdir %s_MaxHomologs_MAX%s_homologs_pfam_output" % (my_fasta[:-6],num_homologs)
os.system(cmd)

for uniprot_id in uniprot_list_total:
	print uniprot_id
	with open("%s_MaxHomologs_MAX%s_homologs_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_homolog.txt" % (my_fasta[:-6],num_homologs, uniprot_id, num_homologs), 'a+') as file_write:
		for max_homolog in range (100, num_homologs+100, 100) :
			print max_homolog
			with open("%s_MaxHomologs_%s_homologs_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_homolog.txt" % (my_fasta[:-6],max_homolog, uniprot_id, max_homolog), 'rU') as file_open:
				data = file_open.readlines()
				for line in data :
					file_write.write("%s" % line)



cmd = "mkdir %s_MaxHomologs_MAX%s_queries_pfam_output" % (my_fasta[:-6],num_homologs)
os.system(cmd)

for uniprot_id in uniprot_list_total:
	print uniprot_id
	with open("%s_MaxHomologs_MAX%s_queries_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_query.txt" % (my_fasta[:-6],num_homologs, uniprot_id, num_homologs), 'a+') as file_write:
		
		for max_homolog in range (100, num_homologs+100, 100) :
			print max_homolog
			with open("%s_MaxHomologs_%s_queries_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_query.txt" % (my_fasta[:-6],max_homolog, uniprot_id, max_homolog), 'rU') as file_open:
				data = file_open.readlines()
				for line in data :
					file_write.write("%s" % line)

	


stop = timeit.default_timer()
print stop - start 

count_pfam_domains_BD.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import re
from Bio import SeqIO # to parse the fasta file
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
import sys
import os
import glob
from collections import Counter


my_fasta = sys.argv[1]
uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)




unp_list, domain_list, Pfam_type_list = [], [], []
for uniprot_id in uniprot_list_total :
	filename = "pfam_in_binding_partners_2038/%s_pfam.txt" % uniprot_id
	if os.path.isfile(filename) == True :
		with open(filename, 'rU') as file_open : 
			data = file_open.readlines()
			for line in data :
				line = line.split("	")
				domain_name = line[6]
				domain_list.append(domain_name)
				unp_id = line[0]
				unp_list.append(unp_id)
		
print 'len(unp_list)', len(unp_list)
print "len(set(unp_list))",len(set(unp_list))
print 'len(domain_list)', len(domain_list)
print "len(set(domain_list))",len(set(domain_list))

count_domain_names = Counter(domain_list)
# print count_domain_names

# count_Pfam_types = Counter(Pfam_type_list)
# for i in count_Pfam_types :
# 	print count_Pfam_types[i], i, "matches, " 


#build dict of total swissprot counts for all SMART domains
Pfam_count_dict, Pfam_description_dict = {},{}
total = 0
with open("FrequenciesPfam_mapped.txt", 'rU') as file_read :
	data = file_read.readlines()
	for line in data[1:] :
		line = line.split("	")
		domain = line[1]
		description = line[-2]
		domain_count_in_swissprot = (line[-1].replace("
",""))
		Pfam_count_dict[domain] = float(domain_count_in_swissprot)
		total = total + Pfam_count_dict[domain]
		Pfam_description_dict[domain] = description
print len(Pfam_count_dict) #14'831
print total #28738352.0

# num_prot_in_swissprot = 18523877
# num_prot_in_subfamily = 510
# with open("hypergeometric_test_Ank_proteins_510_3.txt", 'a+') as file_write :
# 	file_write.write("Domain name	# in Ank proteins	# in Uniprot	p-value <	p-value >
")
# 	for domain_name in count_domain_names :
# 		if domain_name == 'DUF3424' :
# 			pass
# 		else :
# 			domain_count_in_subfamily = float(count_domain_names[domain_name])
# 			domain_count_in_unp = float(Pfam_count_dict[domain_name])
# 			arg3 = float(num_prot_in_swissprot-domain_count_in_unp)
# 			p_val_inf = str(stats.hypergeom.cdf(domain_count_in_subfamily + 1 , domain_count_in_unp, arg3, num_prot_in_subfamily))
# 			p_val_sup = str(stats.hypergeom.cdf(domain_count_in_subfamily - 1 , domain_count_in_unp, arg3 , num_prot_in_subfamily))
# 			file_write.write("%s	%s	%s	%s	%s
" % (domain_name, domain_count_in_subfamily, domain_count_in_unp, p_val_inf, p_val_sup))

import math

num_prot_in_swissprot = 18523877
num_prot_in_subfamily = 2038
with open("Pfam_domains_in_BD_2038.txt", 'a+') as file_write :
	file_write.write("Domain name	# in Binding Partners	# in Uniprot	expected # in Binding Partners	log(obs/exp)
")
	for domain_name in count_domain_names :
		# if domain_name == 'DUF3424' :
		# 	pass
		# else :
		domain_count_in_subfamily = float(count_domain_names[domain_name])
		domain_count_in_unp = float(Pfam_count_dict[domain_name])
		exp_count_in_BD = float(domain_count_in_unp * num_prot_in_subfamily / num_prot_in_swissprot)
		obs_exp = domain_count_in_subfamily/exp_count_in_BD
		file_write.write("%s	%s	%s	%s	%s
" % (domain_name, domain_count_in_subfamily, domain_count_in_unp, exp_count_in_BD, math.log(obs_exp)))
import glob
for filename in glob.iglob("Pfam_domains_in_BD_2038.txt") :
	print filename
	with open(filename, 'rU') as file_read :
		with open("%s_replaced.txt" % filename[:-4], 'a+') as file_write :
			data = file_read.readlines()
			for line in data :
				line = line.replace(".",",")
				file_write.write("%s" % line)




stop = timeit.default_timer()
print stop - start

domain_enrich_conserv_2015.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
from Bio import SeqIO


my_fasta = sys.argv[1]

num_homologs = int(sys.argv[2])

conserv_dict = {}
with open("domain_conservation_percentages_%s.txt" % (num_homologs), 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split()
		domain_name = line[0] 
		domain_conservation = float(line[1].replace("
",""))
		conserv_dict[domain_name] = domain_conservation

average_domain_conservation = sum(conserv_dict.values()) / len(conserv_dict)
print average_domain_conservation


with open("Pfam_domains_in_Ank1234_Zscores.txt", 'rU') as file_open :
	data = file_open.readlines()
	with open("Pfam_domains_in_%s_MaxHomologs_%s_Zscores_color.txt" % (my_fasta,num_homologs), 'a+') as file_write :
		file_write.write("domain_name	domain_enrichment_log(obs/exp)	Zscores_enrichment	domain_conservation_over_%sHomologs	color
" % num_homologs)
		for line in data[1:] :
			line = line.split("	")
			domain_name = line[0]
			domain_enrichment = float(line[4].replace(",", "."))
			domain_enrichment_Zscore = float((line[5].replace(",", ".")).replace("
",""))

			
			if domain_name in conserv_dict :
				domain_conservation = conserv_dict[domain_name]
				if domain_enrichment_Zscore > 1 and domain_conservation > average_domain_conservation:
					color = "\"red\""
				else :
					color = "\"black\""
				file_write.write("%s	%f	%f	%f	%s
" % (domain_name, domain_enrichment, domain_enrichment_Zscore, domain_conservation, color))
			else :
				print "domains %s" % domain_name, "not found in dict"




stop = timeit.default_timer()
print stop - start

domain_enrich_conserv_BD_2015.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
from Bio import SeqIO


my_fasta = sys.argv[1]

num_homologs = int(sys.argv[2])

conserv_dict = {}
with open("domain_conservation_percentages_in_BD_%s.txt" % (num_homologs), 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split()
		domain_name = line[0] 
		domain_conservation = float(line[1].replace("
",""))
		conserv_dict[domain_name] = domain_conservation

average_domain_conservation = sum(conserv_dict.values()) / len(conserv_dict)
print average_domain_conservation


with open("Pfam_domains_in_BD_2038_Zscores.txt", 'rU') as file_open :
	data = file_open.readlines()
	with open("Pfam_domains_in_%s_MaxHomologs_%s_Zscores_color.txt" % (my_fasta,num_homologs), 'a+') as file_write :
		file_write.write("domain_name	domain_enrichment_log(obs/exp)	Zscores_enrichment	domain_conservation_over_%sHomologs	color
" % num_homologs)
		for line in data[1:] :
			line = line.split("	")
			domain_name = line[0]
			domain_enrichment = float(line[4].replace(",", "."))
			domain_enrichment_Zscore = float((line[5].replace(",", ".")).replace("
",""))

			
			if domain_name in conserv_dict :
				domain_conservation = conserv_dict[domain_name]
				if domain_enrichment_Zscore > 1 and domain_conservation > average_domain_conservation:
					color = "\"red\""
				else :
					color = "\"black\""
				file_write.write("%s	%f	%f	%f	%s
" % (domain_name, domain_enrichment, domain_enrichment_Zscore, domain_conservation, color))
			else :
				print "domains %s" % domain_name, "not found in dict"




stop = timeit.default_timer()
print stop - start

general_naming.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math


filename = sys.argv[1]
ma_liste = []
# # general naming
with open(filename, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		ma_liste.append(name)
ma_liste = list(set(ma_liste))


filename2 = sys.argv[2]
ma_liste2 = []
# # general naming
with open(filename2, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		ma_liste2.append(name)
ma_liste2 = list(set(ma_liste2))

overlap = []
for name in ma_liste :
	if name in ma_liste2 :
		print name
		overlap.append(name)

print ", ".join(overlap)

stop = timeit.default_timer()
print stop - start 

get_all_matched_elms_to_domains.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math





domain_file = sys.argv[1]
elm_file = sys.argv[2]


################################################################################################################################################
####################################################      From the domain list : map elms        ###############################################
################################################################################################################################################

						################################################################################################
						######################      no enrichment threshold     ########################################
						################################################################################################


						# Pour chaque domaine trouvé dans famille domain_file :
						# --> assigner le clans
						# --> assigner l'elm interagissant avec le domaine ou clan ssi il se trouve au moins une fois dans la famille elm_file



# domains_that_have_binding_elms_dict = {} #mapping extended to clans
# with open(domain_file,'rU') as file_open : 
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		domain_or_clan = line[1]
# 		binding_elm = line[2]

# 		if binding_elm != 'NULL':
# 			binding_elms = binding_elm.split(", ")
# 			binding_elms = list(set(binding_elms))
# 			domains_that_have_binding_elms_dict[(domain_name, domain_or_clan)] = binding_elms

# print len(domains_that_have_binding_elms_dict)

# elms_found_in_family = []
# with open(elm_file, 'ru') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		binding_domain_or_clan = line[1].split(", ")
# 		binding_domain_or_clan = list(set(binding_domain_or_clan))
# 		elms_found_in_family.append((elm_name,binding_domain_or_clan))
# print len(elms_found_in_family)


# with open("matched_elm_domain_pairs.txt", 'a+') as file_write :
# 	file_write.write("%s	%s	%s	%s
" % ("domain_found_in_family", "corresponding_clan", "binding_elm_found_in_counter_family", "domain_or_clan_to_which_this_elm_binds"))
# 	for domain_tuple in domains_that_have_binding_elms_dict :
# 		for elm_name in domains_that_have_binding_elms_dict[domain_tuple] :
# 			for elm_tuple in elms_found_in_family :
# 				if elm_name in elm_tuple :
# 					domain_found_in_family = domain_tuple[0]
# 					corresponding_clan = domain_tuple[1]
# 					binding_elm_found_in_counter_family = elm_tuple[0]
# 					domain_or_clan_to_which_this_elm_binds = elm_tuple[1]

# 					file_write.write("%s	%s	%s	%s
" % (domain_found_in_family, corresponding_clan, binding_elm_found_in_counter_family, domain_or_clan_to_which_this_elm_binds))




# 						################################################################################################
# 						######################      enrichment threshold : Zscore > 0    ###############################
# 						################################################################################################
						

# 						# Pour chaque domaine avec Zscore > 0 trouvé dans famille domain_file :
# 						# --> assigner le clans
# 						# --> assigner l'elm interagissant avec le domaine ou clan 
# 						# ssi il se trouve dans la famille elm_file
# 						# et ssi il a un Zscore > 0


# domains_that_have_binding_elms_dict = {} #mapping extended to clans
# with open(domain_file,'rU') as file_open : 
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		domain_or_clan = line[1]
# 		binding_elm = line[2]
# 		Zscore = float(line[4])

# 		if Zscore > 0 :

# 			if binding_elm != 'NULL':
# 				binding_elms = binding_elm.split(", ")
# 				binding_elms = list(set(binding_elms))
# 				domains_that_have_binding_elms_dict[(domain_name, domain_or_clan)] = binding_elms

# print len(domains_that_have_binding_elms_dict)


# elms_found_in_family = []
# with open(elm_file, 'ru') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		Zscore = float(line[8])

# 		if Zscore > 0 :

# 			binding_domain_or_clan = line[1].split(", ")
# 			binding_domain_or_clan = list(set(binding_domain_or_clan))
# 			elms_found_in_family.append((elm_name,binding_domain_or_clan))

# print len(elms_found_in_family)


# with open("matched_elm_domain_pairs.txt", 'a+') as file_write :
# 	file_write.write("%s	%s	%s	%s
" % ("domain_found_in_family", "corresponding_clan", "binding_elm_found_in_counter_family", "domain_or_clan_to_which_this_elm_binds"))
# 	for domain_tuple in domains_that_have_binding_elms_dict :
# 		for elm_name in domains_that_have_binding_elms_dict[domain_tuple] :
# 			for elm_tuple in elms_found_in_family :
# 				if elm_name in elm_tuple :
# 					domain_found_in_family = domain_tuple[0]
# 					corresponding_clan = domain_tuple[1]
# 					binding_elm_found_in_counter_family = elm_tuple[0]
# 					domain_or_clan_to_which_this_elm_binds = elm_tuple[1]

# 					file_write.write("%s	%s	%s	%s
" % (domain_found_in_family, corresponding_clan, binding_elm_found_in_counter_family, domain_or_clan_to_which_this_elm_binds))




###############################################################################################################################################
###################################################      From the elm list : map domains       ###############################################
###############################################################################################################################################

						###############################################################################################
						#####################      no enrichment threshold     ########################################
						###############################################################################################


						# Pour chaque elm trouvé dans famille elm_file :
						# --> assigner le domain interagissant avec l'elm ssi il se trouve au moins une fois dans la famille domain_file


# elm_domain_mapping_dict = {}
# with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		domain_name = line[2]
# 		if elm_name not in elm_domain_mapping_dict :
# 			elm_domain_mapping_dict[elm_name] = [domain_name]
# 		else : 
# 			elm_domain_mapping_dict[elm_name].append(domain_name)


# elms_that_have_binding_domain_or_clan_dict = {} 
# with open(elm_file,'rU') as file_open : 
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		binding_domain_or_clan = line[1] 

# 		if elm_name in elm_domain_mapping_dict :
# 			binding_domain_only = elm_domain_mapping_dict[elm_name] #liste!
# 		else :
# 			binding_domain_only = ['NULL']

# 		if binding_domain_or_clan != 'NULL':
# 			binding_domains_or_clans = binding_domain_or_clan.split(", ")
# 			binding_domains_or_clans = list(set(binding_domains_or_clans))
# 			binding_domains_only = list(set(binding_domain_only))
# 			elms_that_have_binding_domain_or_clan_dict[elm_name] = (binding_domains_only, binding_domains_or_clans)

# print len(elms_that_have_binding_domain_or_clan_dict)

# # for i in elms_that_have_binding_domain_or_clan_dict :
# # 	print i, elms_that_have_binding_domain_or_clan_dict[i]

# domains_found_in_family = {}
# with open(domain_file, 'ru') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		corresponding_domain_or_clan = line[1]
# 		binding_elms = line[2].split(", ")
# 		binding_elms = list(set(binding_elms))
# 		domains_found_in_family[domain_name] = (corresponding_domain_or_clan, binding_elms)
# print len(domains_found_in_family)

# # for i in domains_found_in_family :
# # 	print i, domains_found_in_family[i]


# with open("matched_domain_elm_pairs.txt", 'a+') as file_write :
# 	file_write.write("%s	%s	%s	%s
" % ("elm_found_in_family", "binding_domain_found_in_counter_family", "corresponding_clan", "elms_to_which_this_domain_or_clan_binds"))
	
# 	for elm_name in elms_that_have_binding_domain_or_clan_dict :
# 		# print "elm_name", elm_name
		
# 		binding_domains_only = elms_that_have_binding_domain_or_clan_dict[elm_name][0]
# 		# binding_domains_or_clans = elms_that_have_binding_domain_or_clan_dict[elm_name][1]
# 		# print "binding_domains_only", binding_domains_only
# 		# print "binding_domains_or_clans", binding_domains_or_clans

# 		for domain_name in binding_domains_only :
			
# 			if domain_name in domains_found_in_family :
			
# 				elm_found_in_family = elm_name
# 				binding_domain_found_in_counter_family = domain_name
# 				# print "domain_name", domain_name

# 				corresponding_clan = domains_found_in_family[domain_name][0]
# 				# print "corresponding_clan_bis", corresponding_clan_bis

# 				elms_to_which_this_domain_or_clan_binds = domains_found_in_family[domain_name][1]
# 				# print "elms_to_which_this_domain_or_clan_binds", elms_to_which_this_domain_or_clan_binds

# 				file_write.write("%s	%s	%s	%s
" % (elm_found_in_family, binding_domain_found_in_counter_family, corresponding_clan, elms_to_which_this_domain_or_clan_binds))



				




# 						################################################################################################
# 						######################      enrichment threshold : Zscore > 0    ###############################
# 						################################################################################################
						

# 						# Pour chaque elm avec Zscore > 0 trouvé dans famille elm_file :
# 						# --> assigner le domain interagissant avec l'elm
# 						# ssi il se trouve dans la famille domain_file
# 						# et ssi il a un Zscore > 0






elm_domain_mapping_dict = {}
with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		domain_name = line[2]
		if elm_name not in elm_domain_mapping_dict :
			elm_domain_mapping_dict[elm_name] = [domain_name]
		else : 
			elm_domain_mapping_dict[elm_name].append(domain_name)


elms_that_have_binding_domain_or_clan_dict = {} 
with open(elm_file,'rU') as file_open : 
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		binding_domain_or_clan = line[1] 
		Zscore = float(line[8])

		if Zscore > 0 :

			if elm_name in elm_domain_mapping_dict :
				binding_domain_only = elm_domain_mapping_dict[elm_name] #liste!
			else :
				binding_domain_only = ['NULL']

			if binding_domain_or_clan != 'NULL':
				binding_domains_or_clans = binding_domain_or_clan.split(", ")
				binding_domains_or_clans = list(set(binding_domains_or_clans))
				binding_domains_only = list(set(binding_domain_only))
				elms_that_have_binding_domain_or_clan_dict[elm_name] = (binding_domains_only, binding_domains_or_clans)

print len(elms_that_have_binding_domain_or_clan_dict)

# for i in elms_that_have_binding_domain_or_clan_dict :
# 	print i, elms_that_have_binding_domain_or_clan_dict[i]

domains_found_in_family = {}
with open(domain_file, 'ru') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		domain_name = line[0]
		corresponding_domain_or_clan = line[1]
		Zscore = float(line[4])

		if Zscore > 0 :
			binding_elms = line[2].split(", ")
			binding_elms = list(set(binding_elms))
			domains_found_in_family[domain_name] = (corresponding_domain_or_clan, binding_elms)
print len(domains_found_in_family)

# for i in domains_found_in_family :
# 	print i, domains_found_in_family[i]


with open("matched_domain_elm_pairs_Zscore_positive.txt", 'a+') as file_write :
	file_write.write("%s	%s	%s	%s
" % ("elm_found_in_family", "binding_domain_found_in_counter_family", "corresponding_clan", "elms_to_which_this_domain_or_clan_binds"))
	
	for elm_name in elms_that_have_binding_domain_or_clan_dict :
		# print "elm_name", elm_name
		
		binding_domains_only = elms_that_have_binding_domain_or_clan_dict[elm_name][0]
		# binding_domains_or_clans = elms_that_have_binding_domain_or_clan_dict[elm_name][1]
		# print "binding_domains_only", binding_domains_only
		# print "binding_domains_or_clans", binding_domains_or_clans

		for domain_name in binding_domains_only :
			
			if domain_name in domains_found_in_family :
			
				elm_found_in_family = elm_name
				binding_domain_found_in_counter_family = domain_name
				# print "domain_name", domain_name

				corresponding_clan = domains_found_in_family[domain_name][0]
				# print "corresponding_clan_bis", corresponding_clan_bis

				elms_to_which_this_domain_or_clan_binds = domains_found_in_family[domain_name][1]
				# print "elms_to_which_this_domain_or_clan_binds", elms_to_which_this_domain_or_clan_binds

				file_write.write("%s	%s	%s	%s
" % (elm_found_in_family, binding_domain_found_in_counter_family, corresponding_clan, elms_to_which_this_domain_or_clan_binds))















































# filename = sys.argv[1]
# liste = []
# with open(filename, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		name = line[0]
# 		liste.append(name)
# liste = list(set(liste))
# print len(liste)




















































stop = timeit.default_timer()
print stop - start 

get_coocurrences_counters.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math




top_elms_in_ank_proteins = []
top_elms_in_binding_partners = []
top_elms_in_interacting_pairs = []

top_families_in_ank_proteins = []
top_families_in_binding_partners = []
top_families_in_interacting_pairs = []



elm_family_mapping, family_elm_mapping = {}, {}

with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_family = line[1]
		
		if elm_name not in elm_family_mapping :
			elm_family_mapping[elm_name] = [pfam_family]
		else :
			elm_family_mapping[elm_name].append(pfam_family)

		if pfam_family not in family_elm_mapping :
			family_elm_mapping[pfam_family] = [elm_name]
		else :
			family_elm_mapping[pfam_family].append(elm_name)

# for i in family_elm_mapping :
# 	print i, family_elm_mapping[i]
# print "
"
# for i in elm_family_mapping :
# 	print i, elm_family_mapping[i]

# print len(elm_family_mapping), len(family_elm_mapping)


counter1, counter2, counter3, counter4 = 0,0,0,0
counter1bis, counter2bis, counter3bis, counter4bis = 0,0,0,0


with open("interacting_pairs_list_REORDED.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :

		interacting_pair = line.replace("
","")
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		print interacting_pair

################################################################################################################################################
		domains_in_partnerA = []
		domains_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
	#	print partnerA

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerA) == True :
			domain_search_A = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerA).split("
"))

			#print domain_search_A

			for domain in domain_search_A :
				domain_in_A = (domain.split("."))[0]
				domains_in_partnerA.append(domain_in_A)
			
			domains_in_partnerA = list(set(domains_in_partnerA))
			#print domains_in_partnerA

		else :
			#print "%s n'a pas de domains pfam" % partnerA
			pass
		

		#print partnerB


		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))

		#print elms_in_partnerB


		for pfam_family in domains_in_partnerA :
			#print pfam_family
			counter1bis = counter1bis + 1
			if pfam_family in family_elm_mapping :
				binding_elms = family_elm_mapping[pfam_family]
				for elm in binding_elms :
					if elm in elms_in_partnerB :
						counter1 = counter1 + 1
					#	print elm
			else :
				#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
				pass


	# print counter1
	# print counter1bis
	# print "
"


#############################################################################################################################################################################		
		domains_in_partnerA = []
		domains_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerA

		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))

		

		#print partnerB

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerB) == True :
			domain_search_B = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerB).split("
"))

			#print domain_search_A

			for domain in domain_search_B :
				domain_in_B = (domain.split("."))[0]
				domains_in_partnerB.append(domain_in_B)
			
			domains_in_partnerB = list(set(domains_in_partnerB))
			#print domains_in_partnerA

		else :
			#print "%s n'a pas de domains pfam" % partnerB
			pass



		for elm in elms_in_partnerA :
			#print elm
			counter2bis = counter2bis + 1
			if elm in elm_family_mapping :
				binding_domains = elm_family_mapping[elm]
				for domain in binding_domains :
					if domain in domains_in_partnerB :
						counter2 = counter2 + 1
				#		print domain
			else :
				#print "This elm %s was not shown to bind to any domain" % elm
				pass

	# print counter2
	# print counter2bis
	# print "
"
	################################################################################################################################################
		domains_in_partnerA = []
		domains_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerB

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerB) == True :
			domain_search_B = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerB).split("
"))

			#print domain_search_B

			for domain in domain_search_B :
				domain_in_B = (domain.split("."))[0]
				domains_in_partnerB.append(domain_in_B)
			
			domains_in_partnerB = list(set(domains_in_partnerB))
			#print domains_in_partnerB

		else :
			#print "%s n'a pas de domains pfam" % partnerA
			pass
		

		#print partnerB


		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))

		#print elms_in_partnerA


		for pfam_family in domains_in_partnerB :
			#print pfam_family
			counter3bis = counter3bis + 1
			if pfam_family in family_elm_mapping :
				binding_elms = family_elm_mapping[pfam_family]
				for elm in binding_elms :
					if elm in elms_in_partnerA :
						counter3 = counter3+ 1
					#	print elm
			else :
				#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
				pass


	# print counter3
	# print counter3bis
	# print "
"

#############################################################################################################################################################################		
		domains_in_partnerA = []
		domains_in_partnerB = []

		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerB

		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))

		

		#print partnerA

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerA) == True :
			domain_search_A = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerA).split("
"))

			#print domain_search_A

			for domain in domain_search_A :
				domain_in_A = (domain.split("."))[0]
				domains_in_partnerA.append(domain_in_A)
			
			domains_in_partnerA = list(set(domains_in_partnerA))
			#print domains_in_partnerA

		else :
			#print "%s n'a pas de domains pfam" % partnerB
			pass



		for elm in elms_in_partnerB :
			#print elm
			counter4bis = counter4bis + 1
			if elm in elm_family_mapping :
				binding_domains = elm_family_mapping[elm]
				for domain in binding_domains :
					if domain in domains_in_partnerA :
						counter4 = counter4 + 1
						#print domain
			else :
				#print "This elm %s was not shown to bind to any domain" % elm
				pass

	# print counter4
	# print counter4bis
	# print "
"


print counter1
print counter1bis
print "
"
print counter2
print counter2bis
print "
"
print counter3
print counter3bis
print "
"
print counter4
print counter4bis
print "
"

stop = timeit.default_timer()
print stop - start 

get_coocurrences_counters_TOP.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math




top_elms_in_ank_proteins = []
top_elms_in_binding_partners = []
top_elms_in_interacting_pairs = []

top_families_in_ank_proteins = []
top_families_in_binding_partners = []
top_families_in_interacting_pairs = []

with open("top_elms_counts_in_ank_proteins_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_elms_in_ank_proteins.append(name)

with open("top_elms_counts_in_binding_partners_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_elms_in_binding_partners.append(name)

with open("top_elms_counts_in_interacting_pairs_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_elms_in_interacting_pairs.append(name)

with open("top_Pfam_domains_in_all-ank-20130926.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_families_in_ank_proteins.append(name)

with open("top_Pfam_domains_in_binding_partners_2038.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_families_in_binding_partners.append(name)

with open("top_Pfam_domains_in_interacting_pairs_Zscores_colored_with_pfam_clan.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_families_in_interacting_pairs.append(name)


#print top_elms_in_ank_proteins, top_elms_in_binding_partners, top_elms_in_interacting_pairs, top_families_in_ank_proteins, top_families_in_binding_partners, top_families_in_interacting_pairs


elm_family_mapping, family_elm_mapping = {}, {}

with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_family = line[1]
		
		if elm_name not in elm_family_mapping :
			elm_family_mapping[elm_name] = [pfam_family]
		else :
			elm_family_mapping[elm_name].append(pfam_family)

		if pfam_family not in family_elm_mapping :
			family_elm_mapping[pfam_family] = [elm_name]
		else :
			family_elm_mapping[pfam_family].append(elm_name)

# for i in family_elm_mapping :
# 	print i, family_elm_mapping[i]
# print "
"
# for i in elm_family_mapping :
# 	print i, elm_family_mapping[i]

# print len(elm_family_mapping), len(family_elm_mapping)


counter1, counter2, counter3, counter4 = 0,0,0,0
counter1bis, counter2bis, counter3bis, counter4bis = 0,0,0,0


with open("interacting_pairs_list_REORDED.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[:100] :

		interacting_pair = line.replace("
","")
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		print interacting_pair

################################################################################################################################################
		top_elms_in_partnerA = []
		top_elms_in_partnerB = []

		domains_in_partnerA = []
		domains_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
	#	print partnerA

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerA) == True :
			domain_search_A = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerA).split("
"))

			#print domain_search_A

			for domain in domain_search_A :
				domain_in_A = (domain.split("."))[0]
				if domain_in_A in top_families_in_ank_proteins :
					domains_in_partnerA.append(domain_in_A)
			
			domains_in_partnerA = list(set(domains_in_partnerA))
			#print domains_in_partnerA

		else :
			#print "%s n'a pas de domains pfam" % partnerA
			pass
		
		print domains_in_partnerA
		#print partnerB


		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))
		for elm in elms_in_partnerB :
			if elm in top_elms_in_binding_partners:
				top_elms_in_partnerB.append(elm)


		#print elms_in_partnerB
		print top_elms_in_partnerB

		for pfam_family in domains_in_partnerA :
			#print pfam_family
			counter1bis = counter1bis + 1
			if pfam_family in family_elm_mapping :
				binding_elms = family_elm_mapping[pfam_family]
				for elm in binding_elms :
					if elm in top_elms_in_partnerB :
						counter1 = counter1 + 1
					#	print elm
			else :
				#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
				pass


	# print counter1
	# print counter1bis
	# print "
"


#############################################################################################################################################################################		
		top_elms_in_partnerA = []
		top_elms_in_partnerB = []		
		domains_in_partnerA = []
		domains_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerA

		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))
		for elm in elms_in_partnerA :
			if elm in top_elms_in_ank_proteins :
				top_elms_in_partnerA.append(elm)
		

		#print partnerB

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerB) == True :
			domain_search_B = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerB).split("
"))

			#print domain_search_A

			for domain in domain_search_B :
				domain_in_B = (domain.split("."))[0]
				if domain_in_B in top_families_in_binding_partners :
					domains_in_partnerB.append(domain_in_B)
			
			domains_in_partnerB = list(set(domains_in_partnerB))
			#print domains_in_partnerA

		else :
			#print "%s n'a pas de domains pfam" % partnerB
			pass



		for elm in top_elms_in_partnerA :
			#print elm
			counter2bis = counter2bis + 1
			if elm in elm_family_mapping :
				binding_domains = elm_family_mapping[elm]
				for domain in binding_domains :
					if domain in domains_in_partnerB :
						counter2 = counter2 + 1
				#		print domain
			else :
				#print "This elm %s was not shown to bind to any domain" % elm
				pass

	# print counter2
	# print counter2bis
	# print "
"
	################################################################################################################################################
		top_elms_in_partnerA = []
		top_elms_in_partnerB = []			
		domains_in_partnerA = []
		domains_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerB

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerB) == True :
			domain_search_B = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerB).split("
"))

			#print domain_search_B

			for domain in domain_search_B :
				domain_in_B = (domain.split("."))[0]
				if domain_in_B in top_families_in_binding_partners :
					domains_in_partnerB.append(domain_in_B)
			
			domains_in_partnerB = list(set(domains_in_partnerB))
			#print domains_in_partnerB

		else :
			#print "%s n'a pas de domains pfam" % partnerA
			pass
		

		#print partnerB


		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))
		for elm in elms_in_partnerA :
			if elm in top_elms_in_ank_proteins :
				top_elms_in_partnerA.append(elm)
		#print elms_in_partnerA


		for pfam_family in domains_in_partnerB :
			#print pfam_family
			counter3bis = counter3bis + 1
			if pfam_family in family_elm_mapping :
				binding_elms = family_elm_mapping[pfam_family]
				for elm in binding_elms :
					if elm in top_elms_in_partnerA :
						counter3 = counter3+ 1
					#	print elm
			else :
				#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
				pass


	# print counter3
	# print counter3bis
	# print "
"

#############################################################################################################################################################################		
		top_elms_in_partnerA = []
		top_elms_in_partnerB = []	

		domains_in_partnerA = []
		domains_in_partnerB = []

		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerB

		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))
		for elm in elms_in_partnerB :
			if elm in top_elms_in_binding_partners :
				top_elms_in_partnerB.append(elm)
		

		#print partnerA

		if os.path.isfile("pfam_in_interacting_pairs/%s_pfam.txt" % partnerA) == True :
			domain_search_A = (getoutput("awk '{ print $6 }' pfam_in_interacting_pairs/%s_pfam.txt" % partnerA).split("
"))

			#print domain_search_A

			for domain in domain_search_A :
				domain_in_A = (domain.split("."))[0]
				if domain_in_A in top_families_in_ank_proteins :
					domains_in_partnerA.append(domain_in_A)
			
			domains_in_partnerA = list(set(domains_in_partnerA))
			#print domains_in_partnerA

		else :
			#print "%s n'a pas de domains pfam" % partnerB
			pass



		for elm in top_elms_in_partnerB :
			#print elm
			counter4bis = counter4bis + 1
			if elm in elm_family_mapping :
				binding_domains = elm_family_mapping[elm]
				for domain in binding_domains :
					if domain in domains_in_partnerA :
						counter4 = counter4 + 1
						#print domain
			else :
				#print "This elm %s was not shown to bind to any domain" % elm
				pass

	# print counter4
	# print counter4bis
	# print "
"


print counter1
print counter1bis
print "
"
print counter2
print counter2bis
print "
"
print counter3
print counter3bis
print "
"
print counter4
print counter4bis
print "
"

stop = timeit.default_timer()
print stop - start 

get_coocurrences_counters_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_clan_mapping, clan_elm_mapping = {}, {}

with open("elm_interaction_clans_update.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_clan = line[-1].replace("
","")
		
		if pfam_clan != "\N" :

			if elm_name not in elm_clan_mapping :
				elm_clan_mapping[elm_name] = [pfam_clan]
			else :
				elm_clan_mapping[elm_name].append(pfam_clan)

			if pfam_clan not in clan_elm_mapping :
				clan_elm_mapping[pfam_clan] = [elm_name]
			else :
				clan_elm_mapping[pfam_clan].append(elm_name)

print len(clan_elm_mapping), len(elm_clan_mapping)


with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_family = line[1]
		
		if elm_name not in elm_family_mapping :
			elm_family_mapping[elm_name] = [pfam_family]
		else :
			elm_family_mapping[elm_name].append(pfam_family)

		if pfam_family not in family_elm_mapping :
			family_elm_mapping[pfam_family] = [elm_name]
		else :
			family_elm_mapping[pfam_family].append(elm_name)



# for i in clan_elm_mapping :
# 	print i, clan_elm_mapping[i]
# print "
"
# for i in elm_clan_mapping :
# 	print i, elm_clan_mapping[i]


counter1, counter2, counter3, counter4 = 0,0,0,0
counter1bis, counter2bis, counter3bis, counter4bis = 0,0,0,0


with open("interacting_pairs_list.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :

		interacting_pair = line.replace("
","")
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		print interacting_pair

################################################################################################################################################
		clans_in_partnerA = []
		clans_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerA

		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA) == True :
			clan_search_A = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA)).split("
")

			#print clan_search_A

			for clan_in_A in clan_search_A :
				clans_in_partnerA.append(clan_in_A)
			
			clans_in_partnerA = list(set(clans_in_partnerA))
			#print clans_in_partnerA

		else :
			#print "%s n'a pas de clans pfam" % partnerA
			pass
		

		#print partnerB


		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))

		#print elms_in_partnerB


		for pfam_clan in clans_in_partnerA :
			#print pfam_clan
			counter1bis = counter1bis + 1
			if pfam_clan in clan_elm_mapping :
				binding_elms = clan_elm_mapping[pfam_clan]
				for elm in binding_elms :
					if elm in elms_in_partnerB :
						counter1 = counter1 + 1
					#	print elm
			else :
				#print "This Pfam clan %s was not shown to bind to any elm" % pfam_clan
				pass


	# print counter1
	# print counter1bis
	# print "
"


############################################################################################################################################################################		
		clans_in_partnerA = []
		clans_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerA

		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))

		

		#print partnerB

		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB) == True :
			clan_search_B = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB).split("
"))

			#print clan_search_A

			for clan_in_B in clan_search_B :
				clans_in_partnerB.append(clan_in_B)
			
			clans_in_partnerB = list(set(clans_in_partnerB))
			#print clans_in_partnerA

		else :
			#print "%s n'a pas de clans pfam" % partnerB
			pass



		for elm in elms_in_partnerA :
			#print elm
			counter2bis = counter2bis + 1
			if elm in elm_clan_mapping :
				binding_clans = elm_clan_mapping[elm]
				for clan in binding_clans :
					if clan in clans_in_partnerB :
						counter2 = counter2 + 1
				#		print clan
			else :
				#print "This elm %s was not shown to bind to any clan" % elm
				pass

	# print counter2
	# print counter2bis
	# print "
"
	################################################################################################################################################
		clans_in_partnerA = []
		clans_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerB

		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB) == True :
			clan_search_B = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB).split("
"))

			#print clan_search_B

			for clan_in_B in clan_search_B :
				clans_in_partnerB.append(clan_in_B)
			
			clans_in_partnerB = list(set(clans_in_partnerB))
			#print clans_in_partnerB

		else :
			#print "%s n'a pas de clans pfam" % partnerA
			pass
		

		#print partnerB


		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))

		#print elms_in_partnerA


		for pfam_clan in clans_in_partnerB :
			#print pfam_clan
			counter3bis = counter3bis + 1
			if pfam_clan in clan_elm_mapping :
				binding_elms = clan_elm_mapping[pfam_clan]
				for elm in binding_elms :
					if elm in elms_in_partnerA :
						counter3 = counter3+ 1
					#	print elm
			else :
				#print "This Pfam family %s was not shown to bind to any elm" % pfam_clan
				pass


	# print counter3
	# print counter3bis
	# print "
"

#############################################################################################################################################################################		
		clans_in_partnerA = []
		clans_in_partnerB = []

		elms_in_partnerA = []
		elms_in_partnerB = []
		#print partnerB

		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))

		

		#print partnerA

		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA) == True :
			clan_search_A = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA).split("
"))

			#print clan_search_A

			for clan_in_A in clan_search_A :
				clans_in_partnerA.append(clan_in_A)
			
			clans_in_partnerA = list(set(clans_in_partnerA))
			#print clans_in_partnerA

		else :
			#print "%s n'a pas de clans pfam" % partnerB
			pass



		for elm in elms_in_partnerB :
			#print elm
			counter4bis = counter4bis + 1
			if elm in elm_clan_mapping :
				binding_clans = elm_clan_mapping[elm]
				for clan in binding_clans :
					if clan in clans_in_partnerA :
						counter4 = counter4 + 1
						#print clan
			else :
				#print "This elm %s was not shown to bind to any clan" % elm
				pass

	# print counter4
	# print counter4bis
	# print "
"


print counter1
print counter1bis
print "
"
print counter2
print counter2bis
print "
"
print counter3
print counter3bis
print "
"
print counter4
print counter4bis
print "
"

stop = timeit.default_timer()
print stop - start 

get_coocurrences_counters_clans_and_family.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_clan_and_family_mapping, clan_and_family_elm_mapping = {}, {}
elm_names_mapped_to_family_only = []
with open("elm_interaction_clans_update.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_clan = line[-1].replace("
","")
		pfam_family = line[1]


		if pfam_clan != "\N" :

			if elm_name not in elm_clan_and_family_mapping :
				elm_clan_and_family_mapping[elm_name] = [pfam_clan]
			else :
				elm_clan_and_family_mapping[elm_name].append(pfam_clan)

			if pfam_clan not in clan_and_family_elm_mapping :
				clan_and_family_elm_mapping[pfam_clan] = [elm_name]
			else :
				clan_and_family_elm_mapping[pfam_clan].append(elm_name)

		else :
			if elm_name not in elm_clan_and_family_mapping :
				elm_clan_and_family_mapping[elm_name] = [pfam_family]
			else :
				elm_clan_and_family_mapping[elm_name].append(pfam_family)

			if pfam_family not in clan_and_family_elm_mapping :
				clan_and_family_elm_mapping[pfam_family] = [elm_name]
			else :
				clan_and_family_elm_mapping[pfam_family].append(elm_name)

families_concerned = []
for elm_name in elm_clan_and_family_mapping :
	if len(elm_clan_and_family_mapping[elm_name]) == 1 :
		if elm_clan_and_family_mapping[elm_name][0][:2] == "PF" :
			print elm_name, elm_clan_and_family_mapping[elm_name][0]
			elm_names_mapped_to_family_only.append(elm_name)
			families_concerned.append(elm_clan_and_family_mapping[elm_name][0])
families_concerned = list(set(families_concerned))

families_concerned = list(set(families_concerned))
print len(clan_and_family_elm_mapping), len(elm_clan_and_family_mapping), len(elm_names_mapped_to_family_only), len(families_concerned)



# for i in clan_and_family_elm_mapping :
# 	print i, clan_and_family_elm_mapping[i]
# print "
"
# for i in elm_clan_and_family_mapping :
# 	print i, elm_clan_and_family_mapping[i]



	


counter1, counter2, counter3, counter4 = 0,0,0,0
counter1bis, counter2bis, counter3bis, counter4bis = 0,0,0,0


with open("interacting_pairs_list.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[:10] :

		interacting_pair = line.replace("
","")
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		print interacting_pair

####################   SEARCH FOR PFAM STRUCTURE IN A | SEARCH FOR ELM IN B | PFAM IN A --> CORRESPONDING ELM IN B ? ##############
		pfam_clan_search_A = []
		domain_search_A = []
		domains_in_partnerA = []
		domains_in_partnerB = []
		pfam_structures_in_partnerA = []
		pfam_structures_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []

		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA) == True :
			pfam_clan_search_A = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA)).split("
")
			domain_search_A = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA)).split("
")
			
			for domain in domain_search_A :
				domain_in_A = (domain.split("."))[0]
				domains_in_partnerA.append(domain_in_A)

			# print pfam_clan_search_A, domains_in_partnerA
			# print len(pfam_clan_search_A), len(domains_in_partnerA)

			if len(domains_in_partnerA) > 0 :
				for i in range(0,len(domains_in_partnerA)) :
					if pfam_clan_search_A[i][:2] == 'CL' :
						pfam_structures_in_partnerA.append(pfam_clan_search_A[i])
					else :
						pfam_structures_in_partnerA.append(domains_in_partnerA[i])
			else :
				pass		

			pfam_structures_in_partnerA = list(set(pfam_structures_in_partnerA))
			# print pfam_structures_in_partnerA


		else :
			#print "%s n'a pas de pfam_structures" % partnerA
			pass
		



		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))

		print len(elms_in_partnerB), len(pfam_structures_in_partnerA)


		for pfam_structure in pfam_structures_in_partnerA :
			#print pfam_structure
			counter1bis = counter1bis + 1
			if pfam_structure in clan_and_family_elm_mapping :
				binding_elms = clan_and_family_elm_mapping[pfam_structure]
				for elm in binding_elms :
					if elm in elms_in_partnerB :
						counter1 = counter1 + 1
					#	print elm
			else :
				#print "This Pfam clan or family %s was not shown to bind to any elm" % pfam_structure
				pass


	# print counter1
	# print counter1bis
	# print "
"


####################   SEARCH FOR ELM IN A | SEARCH FOR PFAM STRUCTURE IN B | ELM IN A --> CORRESPONDING PFAM IN B ? ##############

		pfam_clan_search_A = []
		domain_search_A = []
		domains_in_partnerA = []
		domains_in_partnerB = []
		pfam_structures_in_partnerA = []
		pfam_structures_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []

		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))



		


		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB) == True :
			pfam_clan_search_B = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB)).split("
")
			domain_search_B = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB)).split("
")
			
			for domain in domain_search_B :
				domain_in_B = (domain.split("."))[0]
				domains_in_partnerB.append(domain_in_B)

			# print pfam_clan_search_B, domains_in_partnerB
			# print len(pfam_clan_search_B), len(domains_in_partnerB)

			if len(domains_in_partnerB) > 0 :
				for i in range(0,len(domains_in_partnerB)) :
					if pfam_clan_search_B[i][:2] == 'CL' :
						pfam_structures_in_partnerB.append(pfam_clan_search_B[i])
					else :
						pfam_structures_in_partnerB.append(domains_in_partnerB[i])
			else :
				pass		

			pfam_structures_in_partnerB = list(set(pfam_structures_in_partnerB))
			# print pfam_structures_in_partnerB


		else :
			#print "%s n'a pas de pfam_structures" % partnerB
			pass

		print len(elms_in_partnerA), len(pfam_structures_in_partnerB)

		for elm in elms_in_partnerA :
			#print elm
			counter2bis = counter2bis + 1
			if elm in elm_clan_and_family_mapping :
				binding_pfam_structures = elm_clan_and_family_mapping[elm]
				for pfam_structure in binding_pfam_structures :
					if pfam_structure in pfam_structures_in_partnerB :
						counter2 = counter2 + 1
				#		print pfam_structure
			else :
				#print "This elm %s was not shown to bind to any pfam_structure" % elm
				pass

	# print counter2
	# print counter2bis
	# print "
"


####################   SEARCH FOR PFAM STRUCTURE IN B | SEARCH FOR ELM IN A | PFAM IN B --> CORRESPONDING ELM IN A ? ##############

		pfam_clan_search_A = []
		domain_search_A = []
		domains_in_partnerA = []
		domains_in_partnerB = []
		pfam_structures_in_partnerA = []
		pfam_structures_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []

		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB) == True :
			pfam_clan_search_B = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB)).split("
")
			domain_search_B = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerB)).split("
")
			
			for domain in domain_search_B :
				domain_in_B = (domain.split("."))[0]
				domains_in_partnerB.append(domain_in_B)

			# print pfam_clan_search_B, domains_in_partnerB
			# print len(pfam_clan_search_B), len(domains_in_partnerB)

			if len(domains_in_partnerB) > 0 :
				for i in range(0,len(domains_in_partnerB)) :
					if pfam_clan_search_B[i][:2] == 'CL' :
						pfam_structures_in_partnerB.append(pfam_clan_search_B[i])
					else :
						pfam_structures_in_partnerB.append(domains_in_partnerB[i])
			else :
				pass		

			pfam_structures_in_partnerB = list(set(pfam_structures_in_partnerB))
			# print pfam_structures_in_partnerB


		else :
			#print "%s n'a pas de pfam_structures" % partnerB
			pass
		

		elms_in_partnerA = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerA).split("
"))))

		#print elms_in_partnerA


		for pfam_structure in pfam_structures_in_partnerB :
			#print pfam_structure
			counter3bis = counter3bis + 1
			if pfam_structure in clan_and_family_elm_mapping :
				binding_elms = clan_and_family_elm_mapping[pfam_structure]
				for elm in binding_elms :
					if elm in elms_in_partnerA :
						counter3 = counter3+ 1
					#	print elm
			else :
				#print "This Pfam family %s was not shown to bind to any elm" % pfam_structure
				pass


	# print counter3
	# print counter3bis
	# print "
"

####################   SEARCH FOR ELM IN B | SEARCH FOR PFAM STRUCTURE IN A | ELM IN B --> CORRESPONDING PFAM IN A ? ##############

		pfam_clan_search_A = []
		domain_search_A = []
		domains_in_partnerA = []
		domains_in_partnerB = []
		pfam_structures_in_partnerA = []
		pfam_structures_in_partnerB = []
		elms_in_partnerA = []
		elms_in_partnerB = []

		elms_in_partnerB = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % partnerB).split("
"))))



		if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA) == True :
			pfam_clan_search_A = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA)).split("
")
			domain_search_A = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % partnerA)).split("
")
			
			for domain in domain_search_A :
				domain_in_A = (domain.split("."))[0]
				domains_in_partnerA.append(domain_in_A)

			# print pfam_clan_search_A, domains_in_partnerA
			# print len(pfam_clan_search_A), len(domains_in_partnerA)

			if len(domains_in_partnerA) > 0 :
				for i in range(0,len(domains_in_partnerA)) :
					if pfam_clan_search_A[i][:2] == 'CL' :
						pfam_structures_in_partnerA.append(pfam_clan_search_A[i])
					else :
						pfam_structures_in_partnerA.append(domains_in_partnerA[i])
			else :
				pass		

			pfam_structures_in_partnerA = list(set(pfam_structures_in_partnerA))
			# print pfam_structures_in_partnerA


		else :
			#print "%s n'a pas de pfam_structures" % partnerA
			pass
		



		for elm in elms_in_partnerB :
			#print elm
			counter4bis = counter4bis + 1
			if elm in elm_clan_and_family_mapping :
				binding_pfam_structures = elm_clan_and_family_mapping[elm]
				for pfam_structure in binding_pfam_structures :
					if pfam_structure in pfam_structures_in_partnerA :
						counter4 = counter4 + 1
						#print pfam_structure
			else :
				#print "This elm %s was not shown to bind to any pfam_structure" % elm
				pass

	# print counter4
	# print counter4bis
	# print "
"


print counter1
print counter1bis
print "
"
print counter2
print counter2bis
print "
"
print counter3
print counter3bis
print "
"
print counter4
print counter4bis
print "
"

stop = timeit.default_timer()
print stop - start 

get_domains_and_clans_enriched_both_in_ank_and_BD.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
import numpy
# from Bio import SeqIO # to parse the fasta file
import collections
import math

domains_in_ank = sys.argv[1]
domains_in_BD = sys.argv[2]




#####################################################################################################
###########################        #based on enrichment > average_value     #########################
#####################################################################################################


# # #average value for enrichment : 
# enrichment_values_in_ank = []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		enrichment = float(line[3])
# 		enrichment_values_in_ank.append(enrichment)
# average_enrichment_in_ank = numpy.mean(enrichment_values_in_ank)
# print average_enrichment_in_ank #3.39631611409


# enrichment_values_in_BD = []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		enrichment = float(line[3])
# 		enrichment_values_in_BD.append(enrichment)
# average_enrichment_in_BD = numpy.mean(enrichment_values_in_BD)
# print average_enrichment_in_BD #2.79198264968



# enriched_domains_in_ank, enriched_clans_in_ank = [], []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > average_enrichment_in_ank :
# 			enriched_domains_in_ank.append(domain_name)
# 			enriched_clans_in_ank.append(clan_name)
# enriched_domains_in_ank = list(set(enriched_domains_in_ank))
# enriched_clans_in_ank = list(set(enriched_clans_in_ank))

# enriched_domains_in_BD, enriched_clans_in_BD = [], []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > average_enrichment_in_BD :
# 			enriched_domains_in_BD.append(domain_name)
# 			enriched_clans_in_BD.append(clan_name)
# enriched_domains_in_BD = list(set(enriched_domains_in_BD))
# enriched_clans_in_BD = list(set(enriched_clans_in_BD))


# enriched_domains_in_ank_and_BD, enriched_clans_in_ank_and_BD = [], []
# for domain_name in enriched_domains_in_ank :
# 	if domain_name in enriched_domains_in_BD :
# 		enriched_domains_in_ank_and_BD.append(domain_name)
# for clan_name in enriched_clans_in_ank :
# 	if clan_name in enriched_clans_in_BD :
# 		enriched_clans_in_ank_and_BD.append(clan_name)

# print "len(enriched_domains_in_ank_and_BD)", len(enriched_domains_in_ank_and_BD) 
# print "len(enriched_clans_in_ank_and_BD)", len(enriched_clans_in_ank_and_BD)

# print enriched_domains_in_ank_and_BD
# print enriched_clans_in_ank_and_BD

# len(enriched_domains_in_ank_and_BD) 22
# len(enriched_clans_in_ank_and_BD) 26
# ['ZU5', 'DBB', 'TRP_2', 'Pre-SET', 'Death', 'Ion_trans', 'EGF', 'Ank_3', 'HECT', 'ZZ', 'PH', 'DUF3354', 'hEGF', 'SH3_2', 'NODP', 'SAM_2', 'Notch', 'PID', 'CAP_GLY', 'DUF3454', 'zf-RanBP', 'RHD']
# ['DBB', 'TRP_2', 'CL0073', 'Pre-SET', 'CL0159', 'ZU5', 'CL0229', 'CL0202', 'CL0125', 'CL0001', 'CL0552', 'CL0006', 'CL0465', 'DUF3354', 'CL0030', 'CL0266', 'CL0033', 'CL0167', 'CL0023', 'CL0041', 'CL0003', 'NODP', 'CL0010', 'Notch', 'CAP_GLY', 'DUF3454']

######################################################################################################
############################        #based on enrichment > 1      ####################################
######################################################################################################

# 
# enriched_domains_in_ank, enriched_clans_in_ank = [], []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > 1 :
# 			enriched_domains_in_ank.append(domain_name)
# 			enriched_clans_in_ank.append(clan_name)
# enriched_domains_in_ank = list(set(enriched_domains_in_ank))
# enriched_clans_in_ank = list(set(enriched_clans_in_ank))

# enriched_domains_in_BD, enriched_clans_in_BD = [], []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > 1 :
# 			enriched_domains_in_BD.append(domain_name)
# 			enriched_clans_in_BD.append(clan_name)
# enriched_domains_in_BD = list(set(enriched_domains_in_BD))
# enriched_clans_in_BD = list(set(enriched_clans_in_BD))


# enriched_domains_in_ank_and_BD, enriched_clans_in_ank_and_BD = [], []
# for domain_name in enriched_domains_in_ank :
# 	if domain_name in enriched_domains_in_BD :
# 		enriched_domains_in_ank_and_BD.append(domain_name)
# for clan_name in enriched_clans_in_ank :
# 	if clan_name in enriched_clans_in_BD :
# 		enriched_clans_in_ank_and_BD.append(clan_name)

# print "len(enriched_domains_in_ank_and_BD)", len(enriched_domains_in_ank_and_BD) 
# print "len(enriched_clans_in_ank_and_BD)", len(enriched_clans_in_ank_and_BD)

# print enriched_domains_in_ank_and_BD
# print enriched_clans_in_ank_and_BD

# len(enriched_domains_in_ank_and_BD) 60
# len(enriched_clans_in_ank_and_BD) 60

# ['TRP_2', 'VPS9', 'Ion_trans', 'PARP', 'TIG', 'EGF', 'Ank_3', 'PID', 'R3H', 'FERM_M', 'cNMP_binding', 'DBB', 'BRCT', 'CAP_GLY', 'SH3_9', 'ArfGap', 'SH2', 'HECT', 'Pkinase_Tyr', 'SH3_1', 'PH', 'G-patch', 'SH3_2', 'SET', 'WGR', 'RHD', 'BTB', 'zf-RanBP', 'PARP_reg', 'Death', 'ZZ', 'Actin', 'zf-CCCH', 'DAGK_cat', 'PDZ', 'WH2', 'Pre-SET', 'LRR_7', 'Myosin_head', 'ZU5', 'Ank', 'Chromo', 'BAR', 'zf-C3HC4_3', 'C1_1', 'hEGF', 'Glutaminase', 'IBR', 'KilA-N', 'DUF3354', 'IQ', 'NODP', 'Notch', 'ELMO_CED12', 'EGF_CA', 'SAM_1', 'TPR_7', 'SAM_2', 'DUF3454', 'OTU']
# ['TRP_2', 'CL0033', 'CL0030', 'VPS9', 'CL0202', 'CL0125', 'CL0459', 'CL0145', 'R3H', 'CL0021', 'CL0020', 'CL0023', 'CL0022', 'FERM_M', 'cNMP_binding', 'DBB', 'CAP_GLY', 'CL0449', 'CL0159', 'ArfGap', 'CL0390', 'CL0229', 'CL0537', 'CL0306', 'CL0167', 'WGR', 'CL0093', 'CL0016', 'CL0541', 'CL0010', 'CL0013', 'PARP_reg', 'CL0073', 'CL0003', 'SET', 'CL0084', 'CL0001', 'CL0552', 'CL0006', 'CL0240', 'CL0108', 'WH2', 'Pre-SET', 'ZU5', 'CL0271', 'CL0384', 'IBR', 'CL0266', 'CL0186', 'DUF3454', 'DUF3354', 'CL0049', 'IQ', 'CL0041', 'NODP', 'Notch', 'ELMO_CED12', 'KilA-N', 'CL0465', 'CL0466']

######################################################################################################
############################        #based on enrichment > 2      ####################################
######################################################################################################


# enriched_domains_in_ank, enriched_clans_in_ank = [], []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > 2 :
# 			enriched_domains_in_ank.append(domain_name)
# 			enriched_clans_in_ank.append(clan_name)
# enriched_domains_in_ank = list(set(enriched_domains_in_ank))
# enriched_clans_in_ank = list(set(enriched_clans_in_ank))

# enriched_domains_in_BD, enriched_clans_in_BD = [], []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > 2 :
# 			enriched_domains_in_BD.append(domain_name)
# 			enriched_clans_in_BD.append(clan_name)
# enriched_domains_in_BD = list(set(enriched_domains_in_BD))
# enriched_clans_in_BD = list(set(enriched_clans_in_BD))


# enriched_domains_in_ank_and_BD, enriched_clans_in_ank_and_BD = [], []
# for domain_name in enriched_domains_in_ank :
# 	if domain_name in enriched_domains_in_BD :
# 		enriched_domains_in_ank_and_BD.append(domain_name)
# for clan_name in enriched_clans_in_ank :
# 	if clan_name in enriched_clans_in_BD :
# 		enriched_clans_in_ank_and_BD.append(clan_name)

# print "len(enriched_domains_in_ank_and_BD)", len(enriched_domains_in_ank_and_BD) 
# print "len(enriched_clans_in_ank_and_BD)", len(enriched_clans_in_ank_and_BD)

# print enriched_domains_in_ank_and_BD
# print enriched_clans_in_ank_and_BD

# len(enriched_domains_in_ank_and_BD) 40
# len(enriched_clans_in_ank_and_BD) 47
# ['TRP_2', 'Ion_trans', 'PARP', 'EGF', 'Ank_3', 'PID', 'FERM_M', 'DBB', 'CAP_GLY', 'SH3_9', 'ArfGap', 'HECT', 'Pkinase_Tyr', 'SH3_1', 'PH', 'SH3_2', 'WGR', 'RHD', 'zf-RanBP', 'PARP_reg', 'Death', 'ZZ', 'DAGK_cat', 'WH2', 'Pre-SET', 'ZU5', 'Chromo', 'BAR', 'zf-C3HC4_3', 'C1_1', 'hEGF', 'IBR', 'DUF3354', 'IQ', 'NODP', 'Notch', 'ELMO_CED12', 'SAM_1', 'SAM_2', 'DUF3454']
# ['TRP_2', 'CL0033', 'CL0030', 'CL0202', 'CL0125', 'CL0145', 'CL0021', 'CL0020', 'CL0023', 'CL0022', 'FERM_M', 'DBB', 'CAP_GLY', 'CL0159', 'ArfGap', 'CL0229', 'CL0537', 'CL0306', 'CL0167', 'WGR', 'CL0093', 'CL0016', 'CL0010', 'PARP_reg', 'CL0073', 'CL0003', 'CL0084', 'CL0001', 'CL0552', 'CL0006', 'CL0240', 'WH2', 'Pre-SET', 'ZU5', 'CL0271', 'IBR', 'CL0266', 'CL0186', 'DUF3454', 'DUF3354', 'CL0049', 'IQ', 'CL0041', 'NODP', 'Notch', 'ELMO_CED12', 'CL0465']


######################################################################################################
############################        #based on enrichment > 3      ####################################
######################################################################################################


# enriched_domains_in_ank, enriched_clans_in_ank = [], []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > 3 :
# 			enriched_domains_in_ank.append(domain_name)
# 			enriched_clans_in_ank.append(clan_name)
# enriched_domains_in_ank = list(set(enriched_domains_in_ank))
# enriched_clans_in_ank = list(set(enriched_clans_in_ank))

# enriched_domains_in_BD, enriched_clans_in_BD = [], []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		enrichment = float(line[3])
# 		if enrichment > 3 :
# 			enriched_domains_in_BD.append(domain_name)
# 			enriched_clans_in_BD.append(clan_name)
# enriched_domains_in_BD = list(set(enriched_domains_in_BD))
# enriched_clans_in_BD = list(set(enriched_clans_in_BD))


# enriched_domains_in_ank_and_BD, enriched_clans_in_ank_and_BD = [], []
# for domain_name in enriched_domains_in_ank :
# 	if domain_name in enriched_domains_in_BD :
# 		enriched_domains_in_ank_and_BD.append(domain_name)
# for clan_name in enriched_clans_in_ank :
# 	if clan_name in enriched_clans_in_BD :
# 		enriched_clans_in_ank_and_BD.append(clan_name)

# print "len(enriched_domains_in_ank_and_BD)", len(enriched_domains_in_ank_and_BD) 
# print "len(enriched_clans_in_ank_and_BD)", len(enriched_clans_in_ank_and_BD)

# print enriched_domains_in_ank_and_BD
# print enriched_clans_in_ank_and_BD

# len(enriched_domains_in_ank_and_BD) 18
# len(enriched_clans_in_ank_and_BD) 27
# ['TRP_2', 'Ion_trans', 'EGF', 'Ank_3', 'PID', 'DBB', 'CAP_GLY', 'HECT', 'SH3_1', 'RHD', 'PARP_reg', 'Death', 'ZZ', 'ZU5', 'DUF3354', 'NODP', 'SAM_2', 'DUF3454']
# ['PARP_reg', 'DBB', 'TRP_2', 'CL0073', 'CL0159', 'ZU5', 'CL0020', 'CL0229', 'CL0202', 'CL0125', 'CL0001', 'CL0552', 'CL0006', 'CL0465', 'DUF3354', 'CL0030', 'CL0266', 'CL0145', 'CL0033', 'CL0167', 'CL0023', 'CL0041', 'CL0003', 'NODP', 'CL0010', 'CAP_GLY', 'DUF3454']


######################################################################################################
############################    based on Zscore enrichment > 1    ####################################
######################################################################################################
# # 
# enriched_domains_in_ank, enriched_clans_in_ank = [], []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		Zscore = float(line[4])
# 		if Zscore > 1 :
# 			enriched_domains_in_ank.append(domain_name)
# 			enriched_clans_in_ank.append(clan_name)
# enriched_domains_in_ank = list(set(enriched_domains_in_ank))
# enriched_clans_in_ank = list(set(enriched_clans_in_ank))

# enriched_domains_in_BD, enriched_clans_in_BD = [], []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		Zscore = float(line[4])
# 		if Zscore > 1 :
# 			enriched_domains_in_BD.append(domain_name)
# 			enriched_clans_in_BD.append(clan_name)
# enriched_domains_in_BD = list(set(enriched_domains_in_BD))
# enriched_clans_in_BD = list(set(enriched_clans_in_BD))


# enriched_domains_in_ank_and_BD, enriched_clans_in_ank_and_BD = [], []
# for domain_name in enriched_domains_in_ank :
# 	if domain_name in enriched_domains_in_BD :
# 		enriched_domains_in_ank_and_BD.append(domain_name)
# for clan_name in enriched_clans_in_ank :
# 	if clan_name in enriched_clans_in_BD :
# 		enriched_clans_in_ank_and_BD.append(clan_name)

# print "len(enriched_domains_in_ank_and_BD)", len(enriched_domains_in_ank_and_BD) 
# print "len(enriched_clans_in_ank_and_BD)", len(enriched_clans_in_ank_and_BD)

# print enriched_domains_in_ank_and_BD
# print enriched_clans_in_ank_and_BD

# len(enriched_domains_in_ank_and_BD) 2
# len(enriched_clans_in_ank_and_BD) 3
# ['DBB', 'TRP_2']
# ['DBB', 'TRP_2', 'CL0229']


######################################################################################################
############################    based on Zscore enrichment > 0.5  ####################################
######################################################################################################
# enriched_domains_in_ank, enriched_clans_in_ank = [], []
# with open(domains_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		Zscore = float(line[4])
# 		if Zscore > 0.5 :
# 			enriched_domains_in_ank.append(domain_name)
# 			enriched_clans_in_ank.append(clan_name)
# enriched_domains_in_ank = list(set(enriched_domains_in_ank))
# enriched_clans_in_ank = list(set(enriched_clans_in_ank))

# enriched_domains_in_BD, enriched_clans_in_BD = [], []
# with open(domains_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		clan_name = line[1]
# 		Zscore = float(line[4])
# 		if Zscore > 0.5 :
# 			enriched_domains_in_BD.append(domain_name)
# 			enriched_clans_in_BD.append(clan_name)
# enriched_domains_in_BD = list(set(enriched_domains_in_BD))
# enriched_clans_in_BD = list(set(enriched_clans_in_BD))


# enriched_domains_in_ank_and_BD, enriched_clans_in_ank_and_BD = [], []
# for domain_name in enriched_domains_in_ank :
# 	if domain_name in enriched_domains_in_BD :
# 		enriched_domains_in_ank_and_BD.append(domain_name)
# for clan_name in enriched_clans_in_ank :
# 	if clan_name in enriched_clans_in_BD :
# 		enriched_clans_in_ank_and_BD.append(clan_name)

# print "len(enriched_domains_in_ank_and_BD)", len(enriched_domains_in_ank_and_BD) 
# print "len(enriched_clans_in_ank_and_BD)", len(enriched_clans_in_ank_and_BD)

# print enriched_domains_in_ank_and_BD
# print enriched_clans_in_ank_and_BD

# len(enriched_domains_in_ank_and_BD) 5
# len(enriched_clans_in_ank_and_BD) 10
# ['DBB', 'TRP_2', 'EGF', 'DUF3454', 'RHD']
# ['DBB', 'TRP_2', 'CL0073', 'CL0159', 'CL0229', 'CL0001', 'CL0023', 'CL0041', 'CL0003', 'DUF3454']







stop = timeit.default_timer()
print stop - start 

get_elms_enriched_both_in_ank_and_BD.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
import numpy
# from Bio import SeqIO # to parse the fasta file
import collections
import math

elms_in_ank = sys.argv[1]
elms_in_BD = sys.argv[2]




# #####################################################################################################
# ###########################        #based on enrichment > average_value     #########################
# #####################################################################################################


# # #average value for enrichment : 
# enrichment_values_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		enrichment = float(line[6])
# 		enrichment_values_in_ank.append(enrichment)
# average_enrichment_in_ank = numpy.mean(enrichment_values_in_ank)
# print average_enrichment_in_ank #0.320082418061


# enrichment_values_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		enrichment = float(line[6])
# 		enrichment_values_in_BD.append(enrichment)
# average_enrichment_in_BD = numpy.mean(enrichment_values_in_BD)
# print average_enrichment_in_BD #0.663061310126



# enriched_elms_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > average_enrichment_in_ank :
# 			enriched_elms_in_ank.append(elm_name)
# enriched_elms_in_ank = list(set(enriched_elms_in_ank))

# enriched_elms_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > average_enrichment_in_BD :
# 			enriched_elms_in_BD.append(elm_name)
# enriched_elms_in_BD = list(set(enriched_elms_in_BD))


# enriched_elms_in_ank_and_BD = []
# for elm_name in enriched_elms_in_ank :
# 	if elm_name in enriched_elms_in_BD :
# 		enriched_elms_in_ank_and_BD.append(elm_name)

# print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

# print enriched_elms_in_ank_and_BD

# len(enriched_elms_in_ank_and_BD) 46
# ['LIG_GLEBS_BUB3_1', 'LIG_Rb_LxCxE_1', 'TRG_ENDOCYTIC_2', 'DOC_PIKK_1', 'MOD_ASX_betaOH_EGF', 'LIG_NRBOX', 'LIG_CORNRBOX', 'DEG_MDM2_1', 'LIG_Rb_pABgroove_1', 'LIG_SH2_PTP2', 'LIG_SPRY_1', 'LIG_Actin_WH2_2', 'LIG_TYR_ITIM', 'LIG_Actin_WH2_1', 'LIG_AP2alpha_1', 'LIG_OCRL_FandH_1', 'LIG_PTB_Phospho_1', 'LIG_BIR_III_3', 'LIG_TYR_ITSM', 'LIG_Actin_RPEL_3', 'DOC_SPAK_OSR1_1', 'LIG_SH2_STAT5', 'DOC_AGCK_PIF_2', 'LIG_FAT_LD_1', 'TRG_PEX_2', 'LIG_PTB_Apo_2', 'LIG_Clathr_ClatBox_2', 'MOD_OFUCOSY', 'LIG_HOMEOBOX', 'TRG_AP2beta_CARGO_1', 'MOD_CMANNOS', 'LIG_EH1_1', 'TRG_NLS_MonoCore_2', 'LIG_TYR_ITAM', 'LIG_PCNA_PIPBox_1', 'DOC_AGCK_PIF_1', 'LIG_Sin3_3', 'LIG_SH2_GRB2', 'MOD_N-GLC_2', 'LIG_CtBP_PxDLS_1', 'MOD_OGLYCOS', 'LIG_eIF4E_1', 'TRG_PEX_1', 'LIG_BIR_III_1', 'LIG_CAP-Gly_1', 'MOD_CAAXbox']




# #####################################################################################################
# ###########################        #based on enrichment > average_value     #########################
# ###########################        and on conservation > average_value     #########################
# #####################################################################################################


# #average value for enrichment : 
enrichment_values_in_ank = []
with open(elms_in_ank, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		enrichment = float(line[6])
		enrichment_values_in_ank.append(enrichment)
average_enrichment_in_ank = numpy.mean(enrichment_values_in_ank)
print average_enrichment_in_ank #0.320082418061


enrichment_values_in_BD = []
with open(elms_in_BD, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		enrichment = float(line[6])
		enrichment_values_in_BD.append(enrichment)
average_enrichment_in_BD = numpy.mean(enrichment_values_in_BD)
print average_enrichment_in_BD #0.663061310126


# #average value for conservation : 
conservation_values_in_ank = []
with open(elms_in_ank, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		conservation = float(line[7])
		conservation_values_in_ank.append(conservation)
average_conservation_in_ank = numpy.mean(conservation_values_in_ank)
print average_conservation_in_ank #0.497151327904



conservation_values_in_BD = []
with open(elms_in_BD, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		conservation = float(line[7])
		conservation_values_in_BD.append(conservation)
average_conservation_in_BD = numpy.mean(conservation_values_in_BD)
print average_conservation_in_BD #0.40097531464



enriched_elms_in_ank = []
with open(elms_in_ank, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		enrichment = float(line[6])
		conservation = float(line[7])
		if enrichment > average_enrichment_in_ank and conservation > average_conservation_in_ank :
			enriched_elms_in_ank.append(elm_name)
enriched_elms_in_ank = list(set(enriched_elms_in_ank))

enriched_elms_in_BD = []
with open(elms_in_BD, 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		enrichment = float(line[6])
		conservation = float(line[7])
		if enrichment > average_enrichment_in_BD and conservation > average_conservation_in_BD :
			enriched_elms_in_BD.append(elm_name)
enriched_elms_in_BD = list(set(enriched_elms_in_BD))


enriched_elms_in_ank_and_BD = []
for elm_name in enriched_elms_in_ank :
	if elm_name in enriched_elms_in_BD :
		enriched_elms_in_ank_and_BD.append(elm_name)

print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

print enriched_elms_in_ank_and_BD








######################################################################################################
############################        #based on enrichment > 1      ####################################
######################################################################################################


# enriched_elms_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > 1 :
# 			enriched_elms_in_ank.append(elm_name)
# enriched_elms_in_ank = list(set(enriched_elms_in_ank))

# enriched_elms_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > 1 :
# 			enriched_elms_in_BD.append(elm_name)
# enriched_elms_in_BD = list(set(enriched_elms_in_BD))


# enriched_elms_in_ank_and_BD = []
# for elm_name in enriched_elms_in_ank :
# 	if elm_name in enriched_elms_in_BD :
# 		enriched_elms_in_ank_and_BD.append(elm_name)

# print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

# print enriched_elms_in_ank_and_BD

# # en(enriched_elms_in_ank_and_BD) 28
# # ['LIG_TYR_ITAM', 'TRG_ENDOCYTIC_2', 'MOD_ASX_betaOH_EGF', 'LIG_eIF4E_1', 'LIG_CORNRBOX', 'DEG_MDM2_1', 'LIG_EH1_1', 'LIG_AP2alpha_1', 'LIG_OCRL_FandH_1', 'LIG_PTB_Phospho_1', 'LIG_GLEBS_BUB3_1', 'LIG_Actin_RPEL_3', 'LIG_SPRY_1', 'LIG_FAT_LD_1', 'TRG_PEX_2', 'LIG_PTB_Apo_2', 'LIG_Clathr_ClatBox_2', 'LIG_NRBOX', 'LIG_HOMEOBOX', 'LIG_PCNA_PIPBox_1', 'DOC_AGCK_PIF_1', 'DOC_AGCK_PIF_2', 'MOD_OGLYCOS', 'LIG_Rb_pABgroove_1', 'LIG_TYR_ITIM', 'MOD_OFUCOSY', 'LIG_CAP-Gly_1', 'MOD_CAAXbox']

######################################################################################################
############################        #based on enrichment > 2      ####################################
######################################################################################################
# enriched_elms_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > 2 :
# 			enriched_elms_in_ank.append(elm_name)
# enriched_elms_in_ank = list(set(enriched_elms_in_ank))

# enriched_elms_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > 2 :
# 			enriched_elms_in_BD.append(elm_name)
# enriched_elms_in_BD = list(set(enriched_elms_in_BD))


# enriched_elms_in_ank_and_BD = []
# for elm_name in enriched_elms_in_ank :
# 	if elm_name in enriched_elms_in_BD :
# 		enriched_elms_in_ank_and_BD.append(elm_name)

# print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

# print enriched_elms_in_ank_and_BD

# len(enriched_elms_in_ank_and_BD) 4
# ['MOD_ASX_betaOH_EGF', 'MOD_OGLYCOS', 'LIG_TYR_ITAM', 'LIG_PCNA_PIPBox_1']

######################################################################################################
############################        #based on enrichment > 3      ####################################
######################################################################################################

# enriched_elms_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > 3 :
# 			enriched_elms_in_ank.append(elm_name)
# enriched_elms_in_ank = list(set(enriched_elms_in_ank))

# enriched_elms_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[6])
# 		if enrichment > 3 :
# 			enriched_elms_in_BD.append(elm_name)
# enriched_elms_in_BD = list(set(enriched_elms_in_BD))


# enriched_elms_in_ank_and_BD = []
# for elm_name in enriched_elms_in_ank :
# 	if elm_name in enriched_elms_in_BD :
# 		enriched_elms_in_ank_and_BD.append(elm_name)

# print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

# print enriched_elms_in_ank_and_BD

# len(enriched_elms_in_ank_and_BD) 2
# ['MOD_OGLYCOS', 'MOD_ASX_betaOH_EGF']

######################################################################################################
############################    based on Zscore enrichment > 1    ####################################
######################################################################################################
# #
# enriched_elms_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		Zscore = float(line[8])
# 		if Zscore > 1 :
# 			enriched_elms_in_ank.append(elm_name)
# enriched_elms_in_ank = list(set(enriched_elms_in_ank))

# enriched_elms_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		Zscore = float(line[8])
# 		if Zscore > 1 :
# 			enriched_elms_in_BD.append(elm_name)
# enriched_elms_in_BD = list(set(enriched_elms_in_BD))


# enriched_elms_in_ank_and_BD = []
# for elm_name in enriched_elms_in_ank :
# 	if elm_name in enriched_elms_in_BD :
# 		enriched_elms_in_ank_and_BD.append(elm_name)

# print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

# print enriched_elms_in_ank_and_BD

# len(enriched_elms_in_ank_and_BD) 6
# ['MOD_ASX_betaOH_EGF', 'MOD_OGLYCOS', 'LIG_TYR_ITAM', 'LIG_CORNRBOX', 'LIG_PCNA_PIPBox_1', 'DOC_AGCK_PIF_1']


######################################################################################################
############################    based on Zscore enrichment > 0.5  ####################################
######################################################################################################

# enriched_elms_in_ank = []
# with open(elms_in_ank, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		Zscore = float(line[8])
# 		if Zscore > 0.5 :
# 			enriched_elms_in_ank.append(elm_name)
# enriched_elms_in_ank = list(set(enriched_elms_in_ank))

# enriched_elms_in_BD = []
# with open(elms_in_BD, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		Zscore = float(line[8])
# 		if Zscore > 0.5 :
# 			enriched_elms_in_BD.append(elm_name)
# enriched_elms_in_BD = list(set(enriched_elms_in_BD))


# enriched_elms_in_ank_and_BD = []
# for elm_name in enriched_elms_in_ank :
# 	if elm_name in enriched_elms_in_BD :
# 		enriched_elms_in_ank_and_BD.append(elm_name)

# print "len(enriched_elms_in_ank_and_BD)", len(enriched_elms_in_ank_and_BD) 

# print enriched_elms_in_ank_and_BD

# len(enriched_elms_in_ank_and_BD) 18
# ['LIG_TYR_ITAM', 'MOD_ASX_betaOH_EGF', 'LIG_CORNRBOX', 'DEG_MDM2_1', 'LIG_EH1_1', 'LIG_AP2alpha_1', 'LIG_Actin_RPEL_3', 'LIG_SPRY_1', 'LIG_FAT_LD_1', 'TRG_PEX_2', 'LIG_HOMEOBOX', 'LIG_PCNA_PIPBox_1', 'DOC_AGCK_PIF_1', 'DOC_AGCK_PIF_2', 'MOD_OGLYCOS', 'LIG_Rb_pABgroove_1', 'MOD_OFUCOSY', 'MOD_CAAXbox']

stop = timeit.default_timer()
print stop - start 

get_elms_list_with_unnatotated_interacting_domains.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_name_list = []
with open("elm_patterns_20140701.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		elm_name_list.append(elm_name)
print len(elm_name_list)


mapped_elms = []
with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		mapped_elms.append(elm_name)
mapped_elms = list(set(mapped_elms))

print len(mapped_elms)


for elm_name in elm_name_list :
	if elm_name not in mapped_elms :
		print elm_name










stop = timeit.default_timer()
print stop - start 

get_intra_coocurrences_counters.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_family_mapping, family_elm_mapping = {}, {}

with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_family = line[1]
		
		if elm_name not in elm_family_mapping :
			elm_family_mapping[elm_name] = [pfam_family]
		else :
			elm_family_mapping[elm_name].append(pfam_family)

		if pfam_family not in family_elm_mapping :
			family_elm_mapping[pfam_family] = [elm_name]
		else :
			family_elm_mapping[pfam_family].append(elm_name)



counter1, counter2 = 0,0
counter1bis, counter2bis = 0,0

ank_and_BD_list = []
with open("interacting_pairs_list_REORDED.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		ank_and_BD_list.append(partnerA)
		ank_and_BD_list.append(partnerB)

ank_and_BD_list = list(set(ank_and_BD_list))
print len(ank_and_BD_list) #2321

# ########################################################################        IN ANK AND BD    ######################################################################		

# for protein in ank_and_BD_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_A

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_partnerA

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_family in domains_in_protein :
# 		#print pfam_family
# 		counter1bis = counter1bis + 1
# 		if pfam_family in family_elm_mapping :
# 			binding_elms = family_elm_mapping[pfam_family]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
# 			pass


# print counter1
# print counter1bis
# print "
"




##########################################################      IN ANKYRINS ONLY        ##########################################################

# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_A

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_partnerA

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_family in domains_in_protein :
# 		#print pfam_family
# 		counter1bis = counter1bis + 1
# 		if pfam_family in family_elm_mapping :
# 			binding_elms = family_elm_mapping[pfam_family]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
# 			pass


# print counter1
# print counter1bis
# print "
"


##########################################################      IN BD ONLY        ##########################################################

# ank_list = []
# BD_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# BD_list = list(set(ank_and_BD_list)-set(ank_list))
# print len(BD_list)
# # 
# for protein in BD_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_A

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_partnerA

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_family in domains_in_protein :
# 		#print pfam_family
# 		counter1bis = counter1bis + 1
# 		if pfam_family in family_elm_mapping :
# 			binding_elms = family_elm_mapping[pfam_family]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
# 			pass


# print counter1
# print counter1bis
# print "
"


# ########################################################################        IN ANK AND BD    ######################################################################		
# for protein in ank_and_BD_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

# 	#print partnerB

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_protein

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_protein

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerB
# 		pass



# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_family_mapping :
# 			binding_domains = elm_family_mapping[elm]
# 			for domain in binding_domains :
# 				if domain in domains_in_protein :
# 					counter2 = counter2 + 1
# 			#		print domain
# 		else :
# 			#print "This elm %s was not shown to bind to any domain" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN ANKYRINS ONLY        ##########################################################
# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

# 	#print partnerB

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_protein

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_protein

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerB
# 		pass



# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_family_mapping :
# 			binding_domains = elm_family_mapping[elm]
# 			for domain in binding_domains :
# 				if domain in domains_in_protein :
# 					counter2 = counter2 + 1
# 			#		print domain
# 		else :
# 			#print "This elm %s was not shown to bind to any domain" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN BD ONLY        ##########################################################
ank_list = []
BD_list = []

with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		ank_id = line[1].replace("
","")
		ank_list.append(ank_id)
ank_list = list(set(ank_list))

BD_list = list(set(ank_and_BD_list)-set(ank_list))
print len(BD_list)
# 
for protein in BD_list :
	print protein

	domains_in_protein = []
	elms_in_protein = []

	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

	#print partnerB

	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

		#print domain_search_protein

		for domain in domain_search_protein :
			domain_in_protein = (domain.split("."))[0]
			domains_in_protein.append(domain_in_protein)
		
		domains_in_protein = list(set(domains_in_protein))
		#print domains_in_protein

	else :
		#print "%s n'a pas de domains pfam" % partnerB
		pass



	for elm in elms_in_protein :
		#print elm
		counter2bis = counter2bis + 1
		if elm in elm_family_mapping :
			binding_domains = elm_family_mapping[elm]
			for domain in binding_domains :
				if domain in domains_in_protein :
					counter2 = counter2 + 1
			#		print domain
		else :
			#print "This elm %s was not shown to bind to any domain" % elm
			pass

print counter2
print counter2bis
print "
"



stop = timeit.default_timer()
print stop - start 

get_intra_coocurrences_counters_TOP.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math



top_elms_in_ank_proteins = []
top_elms_in_binding_partners = []
top_elms_in_interacting_pairs = []

top_families_in_ank_proteins = []
top_families_in_binding_partners = []
top_families_in_interacting_pairs = []

with open("top_elms_counts_in_ank_proteins_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_elms_in_ank_proteins.append(name)

with open("top_elms_counts_in_binding_partners_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_elms_in_binding_partners.append(name)

with open("top_elms_counts_in_interacting_pairs_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_elms_in_interacting_pairs.append(name)

with open("top_Pfam_domains_in_all-ank-20130926.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_families_in_ank_proteins.append(name)

with open("top_Pfam_domains_in_binding_partners_2038.fasta_MaxHomologs_1000_Zscores_color.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_families_in_binding_partners.append(name)

with open("top_Pfam_domains_in_interacting_pairs_Zscores_colored_with_pfam_clan.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		name = line[0]
		top_families_in_interacting_pairs.append(name)


elm_family_mapping, family_elm_mapping = {}, {}

with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_family = line[1]
		
		if elm_name not in elm_family_mapping :
			elm_family_mapping[elm_name] = [pfam_family]
		else :
			elm_family_mapping[elm_name].append(pfam_family)

		if pfam_family not in family_elm_mapping :
			family_elm_mapping[pfam_family] = [elm_name]
		else :
			family_elm_mapping[pfam_family].append(elm_name)



counterC1, counterC2, counterC3, counterC4, counterC5, counterC6 = 0,0,0,0,0,0
counterC1bis, counterC2bis, counterC3bis, counterC4bis, counterC5bis, counterC6bis = 0,0,0,0,0,0

ank_and_BD_list = []
with open("interacting_pairs_list_REORDED.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		ank_and_BD_list.append(partnerA)
		ank_and_BD_list.append(partnerB)

ank_and_BD_list = list(set(ank_and_BD_list))
print len(ank_and_BD_list) #2321

# ########################################################################        IN ANK AND BD    ######################################################################		

# for protein in ank_and_BD_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_A

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_partnerA

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_family in domains_in_protein :
# 		#print pfam_family
# 		counter1bis = counter1bis + 1
# 		if pfam_family in family_elm_mapping :
# 			binding_elms = family_elm_mapping[pfam_family]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
# 			pass


# print counter1
# print counter1bis
# print "
"




##########################################################      IN ANKYRINS ONLY        ##########################################################

# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_A

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_partnerA

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_family in domains_in_protein :
# 		#print pfam_family
# 		counter1bis = counter1bis + 1
# 		if pfam_family in family_elm_mapping :
# 			binding_elms = family_elm_mapping[pfam_family]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
# 			pass


# print counterC1
# print counterC1bis
# print "
"


##########################################################      IN BD ONLY        ##########################################################

# ank_list = []
# BD_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# BD_list = list(set(ank_and_BD_list)-set(ank_list))
# print len(BD_list)
# # 
# for protein in BD_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_A

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_partnerA

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_family in domains_in_protein :
# 		#print pfam_family
# 		counter1bis = counter1bis + 1
# 		if pfam_family in family_elm_mapping :
# 			binding_elms = family_elm_mapping[pfam_family]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_family
# 			pass


# print counter1
# print counter1bis
# print "
"


# ########################################################################        IN ANK AND BD    ######################################################################		
# for protein in ank_and_BD_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

# 	#print partnerB

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_protein

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_protein

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerB
# 		pass



# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_family_mapping :
# 			binding_domains = elm_family_mapping[elm]
# 			for domain in binding_domains :
# 				if domain in domains_in_protein :
# 					counter2 = counter2 + 1
# 			#		print domain
# 		else :
# 			#print "This elm %s was not shown to bind to any domain" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN ANKYRINS ONLY        ##########################################################
# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	domains_in_protein = []
# 	elms_in_protein = []

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

# 	#print partnerB

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print domain_search_protein

# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)
		
# 		domains_in_protein = list(set(domains_in_protein))
# 		#print domains_in_protein

# 	else :
# 		#print "%s n'a pas de domains pfam" % partnerB
# 		pass



# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_family_mapping :
# 			binding_domains = elm_family_mapping[elm]
# 			for domain in binding_domains :
# 				if domain in domains_in_protein :
# 					counter2 = counter2 + 1
# 			#		print domain
# 		else :
# 			#print "This elm %s was not shown to bind to any domain" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN BD ONLY        ##########################################################
ank_list = []
BD_list = []

with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		ank_id = line[1].replace("
","")
		ank_list.append(ank_id)
ank_list = list(set(ank_list))

BD_list = list(set(ank_and_BD_list)-set(ank_list))
print len(BD_list)
# 
for protein in BD_list :
	print protein

	domains_in_protein = []
	elms_in_protein = []

	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

	#print partnerB

	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

		#print domain_search_protein

		for domain in domain_search_protein :
			domain_in_protein = (domain.split("."))[0]
			domains_in_protein.append(domain_in_protein)
		
		domains_in_protein = list(set(domains_in_protein))
		#print domains_in_protein

	else :
		#print "%s n'a pas de domains pfam" % partnerB
		pass



	for elm in elms_in_protein :
		#print elm
		counter2bis = counter2bis + 1
		if elm in elm_family_mapping :
			binding_domains = elm_family_mapping[elm]
			for domain in binding_domains :
				if domain in domains_in_protein :
					counter2 = counter2 + 1
			#		print domain
		else :
			#print "This elm %s was not shown to bind to any domain" % elm
			pass

print counter2
print counter2bis
print "
"



stop = timeit.default_timer()
print stop - start 

get_intra_coocurrences_counters_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_clan_mapping, clan_elm_mapping = {}, {}

with open("elm_interaction_clans_update.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_clan = line[-1].replace("
","")
		
		if pfam_clan != "\N" :

			if elm_name not in elm_clan_mapping :
				elm_clan_mapping[elm_name] = [pfam_clan]
			else :
				elm_clan_mapping[elm_name].append(pfam_clan)

			if pfam_clan not in clan_elm_mapping :
				clan_elm_mapping[pfam_clan] = [elm_name]
			else :
				clan_elm_mapping[pfam_clan].append(elm_name)



# for i in clan_elm_mapping :
# 	print i, clan_elm_mapping[i]
# print "
"
# for i in elm_clan_mapping :
# 	print i, elm_clan_mapping[i]



counter1, counter2 = 0,0
counter1bis, counter2bis = 0,0

ank_and_BD_list = []
with open("interacting_pairs_list_REORDED.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		ank_and_BD_list.append(partnerA)
		ank_and_BD_list.append(partnerB)

ank_and_BD_list = list(set(ank_and_BD_list))
print len(ank_and_BD_list) #2321

########################################################################        IN ANK AND BD    ######################################################################		

# for protein in ank_and_BD_list :
# 	print protein

# 	clans_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print clan_search_A

# 		for clan_in_protein in clan_search_protein :
# 			clans_in_protein.append(clan_in_protein)
		
# 		clans_in_protein = list(set(clans_in_protein))
# 		#print clans_in_partnerA

# 	else :
# 		#print "%s n'a pas de clans pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_clan in clans_in_protein :
# 		#print pfam_clan
# 		counter1bis = counter1bis + 1
# 		if pfam_clan in clan_elm_mapping :
# 			binding_elms = clan_elm_mapping[pfam_clan]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam clan %s was not shown to bind to any elm" % pfam_clan
# 			pass


# print counter1
# print counter1bis
# print "
"




##########################################################      IN ANKYRINS ONLY        ##########################################################

# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	clans_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print clan_search_A

# 		for clan_in_protein in clan_search_protein :
# 			clans_in_protein.append(clan_in_protein)
		
# 		clans_in_protein = list(set(clans_in_protein))
# 		#print clans_in_partnerA

# 	else :
# 		#print "%s n'a pas de clans pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_clan in clans_in_protein :
# 		#print pfam_clan
# 		counter1bis = counter1bis + 1
# 		if pfam_clan in clan_elm_mapping :
# 			binding_elms = clan_elm_mapping[pfam_clan]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_clan
# 			pass


# print counter1
# print counter1bis
# print "
"


##########################################################      IN BD ONLY        ##########################################################

# ank_list = []
# BD_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# BD_list = list(set(ank_and_BD_list)-set(ank_list))
# print len(BD_list)
# # 
# for protein in BD_list :
# 	print protein

# 	clans_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print clan_search_A

# 		for clan_in_protein in clan_search_protein :
# 			clans_in_protein.append(clan_in_protein)
		
# 		clans_in_protein = list(set(clans_in_protein))
# 		#print clans_in_partnerA

# 	else :
# 		#print "%s n'a pas de clans pfam" % partnerA
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_clan in clans_in_protein :
# 		#print pfam_clan
# 		counter1bis = counter1bis + 1
# 		if pfam_clan in clan_elm_mapping :
# 			binding_elms = clan_elm_mapping[pfam_clan]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam family %s was not shown to bind to any elm" % pfam_clan
# 			pass


# print counter1
# print counter1bis
# print "
"


# ########################################################################        IN ANK AND BD    ######################################################################		
# for protein in ank_and_BD_list :
# 	print protein

# 	clans_in_protein = []
# 	elms_in_protein = []

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

# 	#print partnerB

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print clan_search_protein

# 		for clan_in_protein in clan_search_protein :
# 			clans_in_protein.append(clan_in_protein)
		
# 		clans_in_protein = list(set(clans_in_protein))
# 		#print clans_in_protein

# 	else :
# 		#print "%s n'a pas de clans pfam" % partnerB
# 		pass



# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_clan_mapping :
# 			binding_clans = elm_clan_mapping[elm]
# 			for clan in binding_clans :
# 				if clan in clans_in_protein :
# 					counter2 = counter2 + 1
# 			#		print clan
# 		else :
# 			#print "This elm %s was not shown to bind to any clan" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN ANKYRINS ONLY        ##########################################################
# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	clans_in_protein = []
# 	elms_in_protein = []

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

# 	#print partnerB

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

# 		#print clan_search_protein

# 		for clan_in_protein in clan_search_protein :
# 			clans_in_protein.append(clan_in_protein)
		
# 		clans_in_protein = list(set(clans_in_protein))
# 		#print clans_in_protein

# 	else :
# 		#print "%s n'a pas de clans pfam" % partnerB
# 		pass



# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_clan_mapping :
# 			binding_clans = elm_clan_mapping[elm]
# 			for clan in binding_clans :
# 				if clan in clans_in_protein :
# 					counter2 = counter2 + 1
# 			#		print clan
# 		else :
# 			#print "This elm %s was not shown to bind to any clan" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN BD ONLY        ##########################################################
ank_list = []
BD_list = []

with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		ank_id = line[1].replace("
","")
		ank_list.append(ank_id)
ank_list = list(set(ank_list))

BD_list = list(set(ank_and_BD_list)-set(ank_list))
print len(BD_list)
# 
for protein in BD_list :
	print protein

	clans_in_protein = []
	elms_in_protein = []

	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	

	#print partnerB

	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
		clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein).split("
"))

		#print clan_search_protein

		for clan_in_protein in clan_search_protein :
			clans_in_protein.append(clan_in_protein)
		
		clans_in_protein = list(set(clans_in_protein))
		#print clans_in_protein

	else :
		#print "%s n'a pas de clans pfam" % partnerB
		pass



	for elm in elms_in_protein :
		#print elm
		counter2bis = counter2bis + 1
		if elm in elm_clan_mapping :
			binding_clans = elm_clan_mapping[elm]
			for clan in binding_clans :
				if clan in clans_in_protein :
					counter2 = counter2 + 1
			#		print clan
		else :
			#print "This elm %s was not shown to bind to any clan" % elm
			pass

print counter2
print counter2bis
print "
"



stop = timeit.default_timer()
print stop - start 

get_intra_coocurrences_counters_clans_and_family.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math


elm_clan_and_family_mapping, clan_and_family_elm_mapping = {}, {}
elm_names_mapped_to_family_only = []
with open("elm_interaction_clans_update.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		pfam_clan = line[-1].replace("
","")
		pfam_family = line[1]


		if pfam_clan != "\N" :

			if elm_name not in elm_clan_and_family_mapping :
				elm_clan_and_family_mapping[elm_name] = [pfam_clan]
			else :
				elm_clan_and_family_mapping[elm_name].append(pfam_clan)

			if pfam_clan not in clan_and_family_elm_mapping :
				clan_and_family_elm_mapping[pfam_clan] = [elm_name]
			else :
				clan_and_family_elm_mapping[pfam_clan].append(elm_name)

		else :
			if elm_name not in elm_clan_and_family_mapping :
				elm_clan_and_family_mapping[elm_name] = [pfam_family]
			else :
				elm_clan_and_family_mapping[elm_name].append(pfam_family)

			if pfam_family not in clan_and_family_elm_mapping :
				clan_and_family_elm_mapping[pfam_family] = [elm_name]
			else :
				clan_and_family_elm_mapping[pfam_family].append(elm_name)

families_concerned = []
for elm_name in elm_clan_and_family_mapping :
	if len(elm_clan_and_family_mapping[elm_name]) == 1 :
		if elm_clan_and_family_mapping[elm_name][0][:2] == "PF" :
			print elm_name, elm_clan_and_family_mapping[elm_name][0]
			elm_names_mapped_to_family_only.append(elm_name)
			families_concerned.append(elm_clan_and_family_mapping[elm_name][0])
families_concerned = list(set(families_concerned))

families_concerned = list(set(families_concerned))
print len(clan_and_family_elm_mapping), len(elm_clan_and_family_mapping), len(elm_names_mapped_to_family_only), len(families_concerned)



# for i in clan_elm_mapping :
# 	print i, clan_elm_mapping[i]
# print "
"
# for i in elm_clan_mapping :
# 	print i, elm_clan_mapping[i]



counter1, counter2 = 0,0
counter1bis, counter2bis = 0,0

ank_and_BD_list = []
with open("interacting_pairs_list_REORDED.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")
		ank_and_BD_list.append(partnerA)
		ank_and_BD_list.append(partnerB)

ank_and_BD_list = list(set(ank_and_BD_list))
print len(ank_and_BD_list) #2321

########################################################################        IN ANK AND BD    ######################################################################		

# for protein in ank_and_BD_list :
# 	print protein

# 	pfam_clan_search_protein = []
# 	domain_search_protein = []
# 	domains_in_protein = []
# 	pfam_structures_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		pfam_clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		
# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)

# 		# print pfam_clan_search_protein, domains_in_protein
# 		# print len(pfam_clan_search_protein), len(domains_in_protein)

# 		if len(domains_in_protein) > 0 :
# 			for i in range(0,len(domains_in_protein)) :
# 				if pfam_clan_search_protein[i][:2] == 'CL' :
# 					pfam_structures_in_protein.append(pfam_clan_search_protein[i])
# 				else :
# 					pfam_structures_in_protein.append(domains_in_protein[i])
# 		else :
# 			pass		

# 		pfam_structures_in_protein = list(set(pfam_structures_in_protein))
# 		# print pfam_structures_in_protein


# 	else :
# 		#print "%s n'a pas de pfam_structures" % protein
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_structure in pfam_structures_in_protein :
# 		#print pfam_structure
# 		counter1bis = counter1bis + 1
# 		if pfam_structure in clan_and_family_elm_mapping :
# 			binding_elms = clan_and_family_elm_mapping[pfam_structure]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam structure %s was not shown to bind to any elm" % pfam_structure
# 			pass


# print counter1
# print counter1bis
# print "
"




##########################################################      IN ANKYRINS ONLY        ##########################################################

# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	pfam_clan_search_protein = []
# 	domain_search_protein = []
# 	domains_in_protein = []
# 	pfam_structures_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		pfam_clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		
# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)

# 		# print pfam_clan_search_protein, domains_in_protein
# 		# print len(pfam_clan_search_protein), len(domains_in_protein)

# 		if len(domains_in_protein) > 0 :
# 			for i in range(0,len(domains_in_protein)) :
# 				if pfam_clan_search_protein[i][:2] == 'CL' :
# 					pfam_structures_in_protein.append(pfam_clan_search_protein[i])
# 				else :
# 					pfam_structures_in_protein.append(domains_in_protein[i])
# 		else :
# 			pass		

# 		pfam_structures_in_protein = list(set(pfam_structures_in_protein))
# 		# print pfam_structures_in_protein


# 	else :
# 		#print "%s n'a pas de pfam_structures" % protein
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_structure in pfam_structures_in_protein :
# 		#print pfam_structure
# 		counter1bis = counter1bis + 1
# 		if pfam_structure in clan_and_family_elm_mapping :
# 			binding_elms = clan_and_family_elm_mapping[pfam_structure]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam structure %s was not shown to bind to any elm" % pfam_structure
# 			pass


# print counter1
# print counter1bis
# print "
"


##########################################################      IN BD ONLY        ##########################################################

# ank_list = []
# BD_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# BD_list = list(set(ank_and_BD_list)-set(ank_list))
# print len(BD_list)
# # 
# for protein in BD_list :
# 	print protein

# 	pfam_clan_search_protein = []
# 	domain_search_protein = []
# 	domains_in_protein = []
# 	pfam_structures_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		pfam_clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		
# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)

# 		# print pfam_clan_search_protein, domains_in_protein
# 		# print len(pfam_clan_search_protein), len(domains_in_protein)

# 		if len(domains_in_protein) > 0 :
# 			for i in range(0,len(domains_in_protein)) :
# 				if pfam_clan_search_protein[i][:2] == 'CL' :
# 					pfam_structures_in_protein.append(pfam_clan_search_protein[i])
# 				else :
# 					pfam_structures_in_protein.append(domains_in_protein[i])
# 		else :
# 			pass		

# 		pfam_structures_in_protein = list(set(pfam_structures_in_protein))
# 		# print pfam_structures_in_protein


# 	else :
# 		#print "%s n'a pas de pfam_structures" % protein
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for pfam_structure in pfam_structures_in_protein :
# 		#print pfam_structure
# 		counter1bis = counter1bis + 1
# 		if pfam_structure in clan_and_family_elm_mapping :
# 			binding_elms = clan_and_family_elm_mapping[pfam_structure]
# 			for elm in binding_elms :
# 				if elm in elms_in_protein :
# 					counter1 = counter1 + 1
# 				#	print elm
# 		else :
# 			#print "This Pfam structure %s was not shown to bind to any elm" % pfam_structure
# 			pass


# print counter1
# print counter1bis
# print "
"


# ########################################################################        IN ANK AND BD    ######################################################################		
# for protein in ank_and_BD_list :
# 	print protein

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))


# 	pfam_clan_search_protein = []
# 	domain_search_protein = []
# 	domains_in_protein = []
# 	pfam_structures_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		pfam_clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		
# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)

# 		# print pfam_clan_search_protein, domains_in_protein
# 		# print len(pfam_clan_search_protein), len(domains_in_protein)

# 		if len(domains_in_protein) > 0 :
# 			for i in range(0,len(domains_in_protein)) :
# 				if pfam_clan_search_protein[i][:2] == 'CL' :
# 					pfam_structures_in_protein.append(pfam_clan_search_protein[i])
# 				else :
# 					pfam_structures_in_protein.append(domains_in_protein[i])
# 		else :
# 			pass		

# 		pfam_structures_in_protein = list(set(pfam_structures_in_protein))
# 		# print pfam_structures_in_protein


# 	else :
# 		#print "%s n'a pas de pfam_structures" % protein
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_clan_and_family_mapping :
# 			binding_pfam_structures = elm_clan_and_family_mapping[elm]
# 			for pfam_structure in binding_pfam_structures :
# 				if pfam_structure in pfam_structures_in_protein :
# 					counter2 = counter2 + 1
# 			#		print clan
# 		else :
# 			#print "This elm %s was not shown to bind to any clan" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN ANKYRINS ONLY        ##########################################################
# ank_list = []

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		ank_id = line[1].replace("
","")
# 		ank_list.append(ank_id)
# ank_list = list(set(ank_list))

# for protein in ank_list :
# 	print protein

# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))


# 	pfam_clan_search_protein = []
# 	domain_search_protein = []
# 	domains_in_protein = []
# 	pfam_structures_in_protein = []
# 	elms_in_protein = []

# 	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
# 		pfam_clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
# 		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		
# 		for domain in domain_search_protein :
# 			domain_in_protein = (domain.split("."))[0]
# 			domains_in_protein.append(domain_in_protein)

# 		# print pfam_clan_search_protein, domains_in_protein
# 		# print len(pfam_clan_search_protein), len(domains_in_protein)

# 		if len(domains_in_protein) > 0 :
# 			for i in range(0,len(domains_in_protein)) :
# 				if pfam_clan_search_protein[i][:2] == 'CL' :
# 					pfam_structures_in_protein.append(pfam_clan_search_protein[i])
# 				else :
# 					pfam_structures_in_protein.append(domains_in_protein[i])
# 		else :
# 			pass		

# 		pfam_structures_in_protein = list(set(pfam_structures_in_protein))
# 		# print pfam_structures_in_protein


# 	else :
# 		#print "%s n'a pas de pfam_structures" % protein
# 		pass



# 	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

# 	#print elms_in_partnerB


# 	for elm in elms_in_protein :
# 		#print elm
# 		counter2bis = counter2bis + 1
# 		if elm in elm_clan_and_family_mapping :
# 			binding_pfam_structures = elm_clan_and_family_mapping[elm]
# 			for pfam_structure in binding_pfam_structures :
# 				if pfam_structure in pfam_structures_in_protein :
# 					counter2 = counter2 + 1
# 			#		print clan
# 		else :
# 			#print "This elm %s was not shown to bind to any clan" % elm
# 			pass

# print counter2
# print counter2bis
# print "
"

##########################################################      IN BD ONLY        ##########################################################
ank_list = []
BD_list = []

with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		ank_id = line[1].replace("
","")
		ank_list.append(ank_id)
ank_list = list(set(ank_list))

BD_list = list(set(ank_and_BD_list)-set(ank_list))
print len(BD_list)
# 
for protein in BD_list :
	print protein

	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))


	pfam_clan_search_protein = []
	domain_search_protein = []
	domains_in_protein = []
	pfam_structures_in_protein = []
	elms_in_protein = []

	if os.path.isfile("pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein) == True :
		pfam_clan_search_protein = (getoutput("awk '{ print $15 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		domain_search_protein = (getoutput("awk '{ print $6 }' pfam_in_all_ank1234_and_BD/%s_pfam.txt" % protein)).split("
")
		
		for domain in domain_search_protein :
			domain_in_protein = (domain.split("."))[0]
			domains_in_protein.append(domain_in_protein)

		# print pfam_clan_search_protein, domains_in_protein
		# print len(pfam_clan_search_protein), len(domains_in_protein)

		if len(domains_in_protein) > 0 :
			for i in range(0,len(domains_in_protein)) :
				if pfam_clan_search_protein[i][:2] == 'CL' :
					pfam_structures_in_protein.append(pfam_clan_search_protein[i])
				else :
					pfam_structures_in_protein.append(domains_in_protein[i])
		else :
			pass		

		pfam_structures_in_protein = list(set(pfam_structures_in_protein))
		# print pfam_structures_in_protein


	else :
		#print "%s n'a pas de pfam_structures" % protein
		pass



	elms_in_protein = list(set((getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt | awk '{ print $2 }'" % protein).split("
"))))

	#print elms_in_partnerB


	for elm in elms_in_protein :
		#print elm
		counter2bis = counter2bis + 1
		if elm in elm_clan_and_family_mapping :
			binding_pfam_structures = elm_clan_and_family_mapping[elm]
			for pfam_structure in binding_pfam_structures :
				if pfam_structure in pfam_structures_in_protein :
					counter2 = counter2 + 1
			#		print clan
		else :
			#print "This elm %s was not shown to bind to any clan" % elm
			pass

print counter2
print counter2bis
print "
"



stop = timeit.default_timer()
print stop - start 

get_numbers.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math


# filename = sys.argv[1]
# # filename2 = sys.argv[2]

# elm_list = []

# # general counting
# with open(filename, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		elm_list.append(elm_name)
# elm_list = list(set(elm_list))
# print len(elm_list)

# clv, deg, doc, lig, mod, trg = 0,0,0,0,0,0
# for elm_name in elm_list :
# 	if elm_name[:3] == 'CLV' :
# 		clv+=1
# 	elif elm_name[:3] == 'DEG' :
# 		deg+=1
# 	elif elm_name[:3] == 'DOC' :
# 		doc+=1
# 	elif elm_name[:3] == 'LIG' :
# 		lig+=1
# 	elif elm_name[:3] == 'MOD' :
# 		mod+=1
# 	elif elm_name[:3] == 'TRG' :
# 		trg+=1

# # enriched elms
# with open(filename, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[5])
# 		if enrichment >= 1 :
# 			elm_list.append(elm_name)
# elm_list = list(set(elm_list))
# print len(elm_list)

# clv, deg, doc, lig, mod, trg = 0,0,0,0,0,0
# for elm_name in elm_list :
# 	if elm_name[:3] == 'CLV' :
# 		clv+=1
# 	elif elm_name[:3] == 'DEG' :
# 		deg+=1
# 	elif elm_name[:3] == 'DOC' :
# 		doc+=1
# 	elif elm_name[:3] == 'LIG' :
# 		lig+=1
# 	elif elm_name[:3] == 'MOD' :
# 		mod+=1
# 	elif elm_name[:3] == 'TRG' :
# 		trg+=1

# # enriched and conserved elms
# with open(filename, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		enrichment = float(line[5]) 
# 		if enrichment >= 1 :
# 			color = line[-1].replace("
","")
# 			if color == '\"red\"' :
# 				elm_list.append(elm_name)

# elm_list = list(set(elm_list))
# print len(elm_list)
# print "%s" % (", ". join(elm_list))

# clv, deg, doc, lig, mod, trg = 0,0,0,0,0,0
# for elm_name in elm_list :
# 	if elm_name[:3] == 'CLV' :
# 		clv+=1
# 	elif elm_name[:3] == 'DEG' :
# 		deg+=1
# 	elif elm_name[:3] == 'DOC' :
# 		doc+=1
# 	elif elm_name[:3] == 'LIG' :
# 		lig+=1
# 	elif elm_name[:3] == 'MOD' :
# 		mod+=1
# 	elif elm_name[:3] == 'TRG' :
# 		trg+=1

# print "clv, deg, doc, lig, mod, trg"
# print clv, deg, doc, lig, mod, trg


# # extract some elm domain mapping and store binding domains
# elm_list = ["LIG_WRPW_1", "MOD_SPalmitoyl_4", "LIG_TPR", "MOD_ASX_betaOH_EGF", "LIG_WH1", "LIG_PCNA_PIPBox_1", "MOD_TYR_CSK", "LIG_Sin3_1", "DOC_AGCK_PIF_1"]
# binding_domain_list = []
# with open(filename, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		binding_domain = line[2]
# 		if elm_name in elm_list :
# 			print "%s" % ("	".join(line))
# 			binding_domain_list.append(binding_domain)

# binding_domain_list = list(set(binding_domain_list))
# print len(binding_domain_list)
# print "
"
# # extract some domains binding certain elms
# with open(filename2, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_name = line[0]
# 		if domain_name in binding_domain_list : 
# 			print "%s" % ("	".join(line))

# # extract some elm clan/domain mapping and store binding clan/domain
# elm_list = ["LIG_WRPW_1", "MOD_SPalmitoyl_4", "LIG_TPR", "MOD_ASX_betaOH_EGF", "LIG_WH1", "LIG_PCNA_PIPBox_1", "MOD_TYR_CSK", "LIG_Sin3_1", "DOC_AGCK_PIF_1"]
# binding_clan_or_domain_list = []
# with open(filename, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		binding_domain_or_clan = line[1].replace("
","")
# 		if elm_name in elm_list :
# 			print "%s" % ("	".join(line))
# 			binding_clan_or_domain_list.append(binding_domain_or_clan)

# binding_clan_or_domain_list = list(set(binding_clan_or_domain_list))
# print len(binding_clan_or_domain_list)
# print "
"
# # extract some domains binding certain elms
# with open(filename2, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		domain_or_clan_name = line[1].replace("
","")
# 		if domain_or_clan_name in binding_clan_or_domain_list : 
# 			print "%s" % ("	".join(line[:4]))


# # get Zscore for a list of specific domains :
# domains_data = sys.argv[1]
# domains_list = ["zf-DHHC",
# "DZR",
# "zf-RanBP",
# "zf-NADH-PPase",
# "PH",
# "GRAM",
# "PH_8",
# "PID",
# "Pkinase_Tyr",
# "Pkinase",
# "TPR_8",
# "TPR_2",
# "Arm",
# "TPR_11",
# "TPR_7",
# "RCC1"]
# with open(domains_data, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for domain_name_from_list in domains_list :

# 		for line in data[1:] :
# 			line = line.split("	")
# 			domain_name = line[0]
# 			Zscore = float(line[4])
# 			if domain_name == domain_name_from_list :
# 				print line[0], line[1], line[3], line[4]


# get enrichment score for a list of specific domains :
domains_data = sys.argv[1]
domains_list = ['ZU5', 'DBB', 'TRP_2', 'Pre-SET', 'Death', 'Ion_trans', 'EGF', 'Ank_3', 'HECT', 'ZZ', 'PH', 'DUF3354', 'hEGF', 'SH3_2', 'NODP', 'SAM_2', 'Notch', 'PID', 'CAP_GLY', 'DUF3454', 'zf-RanBP', 'RHD']

with open(domains_data, 'rU') as file_open :
	data = file_open.readlines()
	for domain_name_from_list in domains_list :

		for line in data[1:] :
			line = line.split("	")
			domain_name = line[0]
			enrichment = float(line[3])
			if domain_name == domain_name_from_list :
				print "	".join(line[0:-2])

# get mapping clans from ELM list : 
# elms_data = sys.argv[1]
# elms_list = ["LIG_EH1_1",
# "LIG_FAT_LD_1",
# "DEG_MDM2_1",
# "LIG_NRBOX",
# "MOD_OGLYCOS",
# "TRG_ER_FFAT_1",
# "DOC_AGCK_PIF_1",
# "MOD_ASX_betaOH_EGF",
# "LIG_SPRY_1"]
# with open(elms_data, 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data[1:] :
# 		line = line.split("	")
# 		elm_name = line[0]
# 		clan_or_domain_name = line[1].replace("
","")
# 		if elm_name in elms_list :
# 			print elm_name, clan_or_domain_name



stop = timeit.default_timer()
print stop - start 

interacting_pairs_domains_concaten.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math


cmd = "mkdir domains_in_interacting_pairs"
os.system(cmd)

with open("interacting_pairs_list.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		interacting_pair = line.replace("
","")
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")

		domain_search_A = getoutput("grep \"%s\" pfam_in_interacting_pairs/%s_pfam.txt" % (partnerA,partnerA))
		domain_search_B = getoutput("grep \"%s\" pfam_in_interacting_pairs/%s_pfam.txt" % (partnerB,partnerB))

		with open("domains_in_interacting_pairs/domains_in_%s.txt" % interacting_pair , 'a+') as file_write :
			file_write.write("%s
" % (domain_search_A))
			file_write.write("%s
" % (domain_search_B))






stop = timeit.default_timer()
print stop - start 

interacting_pairs_elms_concaten.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math


cmd = "mkdir elms_in_interacting_pairs"
os.system(cmd)

with open("interacting_pairs_list.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		interacting_pair = line.replace("
","")
		partnerA = line[0:6]
		partnerB = line[7:].replace("
","")

		elm_search_A = getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt" % partnerA)
		elm_search_B = getoutput("grep \"%s\" elms_search_in_interacting_pairs.txt" % partnerB)

		with open("elms_in_interacting_pairs/elms_in_%s.txt" % interacting_pair , 'a+') as file_write :
			file_write.write("%s
" % (elm_search_A))
			file_write.write("%s
" % (elm_search_B))






stop = timeit.default_timer()
print stop - start 

make_binding_pairs_unp.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math


# binding_partners_mapping_dict, ank_mapping_dict, merged_mapping_dict = {}, {}, {}

# with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		string_id = line[0].upper()
# 		unp_id = line[1].replace("
","")
# 		ank_mapping_dict[string_id] = unp_id
# 		merged_mapping_dict[string_id] = unp_id

# with open("binding_partners_mapping_fused12_UPPERCASE.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	for line in data :
# 		line = line.split("	")
# 		string_id = line[0].upper()
# 		unp_id = line[1].replace("
","")
# 		binding_partners_mapping_dict[string_id] = unp_id
# 		if string_id not in merged_mapping_dict :
# 			merged_mapping_dict[string_id] = unp_id
# 		else :
# 			print string_id

# print len(ank_mapping_dict), len(binding_partners_mapping_dict), len(merged_mapping_dict)


# partnerA_list, partnerB_list, indep_proteins = [], [], []

# with open("binding_uniref50_score500_reduced.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	with open("binding_uniref50_score500_reduced_unp_MAPPED.txt", 'a+') as file_write :
# 		with open("unmapped_binding_partners.txt", 'a+') as file_write2 :
# 			for line in data :
# 				line = line.split("	")
# 				partnerA = line[0].upper()
# 				partnerA_list.append(partnerA)
# 				partnerB = line[1].upper()
# 				partnerB_list.append(partnerB)
# 				indep_proteins.append(partnerA)
# 				indep_proteins.append(partnerB)
# 				binding_score = line[5]
# 				if line[6] != '' :
# 					source = line[6].replace("
","")
# 				else :
# 					source = line[7].replace("
","")

# 				if partnerA in merged_mapping_dict :
# 					partnerA_unp = merged_mapping_dict[partnerA]
# 				else :
# 					file_write2.write("%s (unmapped)	%s	%s	%s
" % (partnerA, partnerB, binding_score, source))
				
# 				if partnerB in merged_mapping_dict :
# 					partnerB_unp = merged_mapping_dict[partnerB]
# 				else :
# 					file_write2.write("%s	%s (unmapped)	%s	%s
" % (partnerA, partnerB, binding_score, source))

# 				if partnerA not in merged_mapping_dict and partnerB not in merged_mapping_dict :
# 					print "REALLY?"

# 				if partnerA in merged_mapping_dict and partnerB in merged_mapping_dict :
# 					file_write.write("%s	%s	%s	%s
" % (partnerA_unp, partnerB_unp, binding_score, source))



# indep_proteins = list(set(indep_proteins))	

# print len(partnerA_list), len(set(partnerA_list))
# print len(partnerB_list), len(set(partnerB_list))
# print len(indep_proteins)


with open("binding_uniref50_score500_reduced_unp_MAPPED.txt", 'rU') as file_open :
	data = file_open.readlines()
	with open("interacting_pairs_list.txt", 'a+') as file_write :
		for line in data :
			line = line.split("	")
			partnerA = line[0]
			partnerB = line[1]
			interacting_pair = "%s_%s" % (partnerA, partnerB)
			file_write.write("%s
" % interacting_pair)



stop = timeit.default_timer()
print stop - start 

make_fasta.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
from Bio import SeqIO


my_fasta = sys.argv[1]
uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)


with open("check_pfam_in_%s" % my_fasta, 'a+') as file_write_query : 
	with open("check_pfam_in_%s_homolog_hits.fasta" % (my_fasta[:-6]), 'a+') as file_write_hit : 

		for uniprot_id in uniprot_list_total :

			domain_dict = {}
			filename = "pfam_in_%s/%s_pfam.txt" % (my_fasta[:-6], uniprot_id)
			if os.path.isfile(filename) == True :
				print uniprot_id

				with open(filename, 'rU') as file_open :
					data = file_open.readlines()
					for line in data :
						line = line.split("	")
						domain_start = int(line[1])
						domain_end = int(line[2])
						domain_id = line[5]
						if (domain_start, domain_end) not in domain_dict :
							domain_dict[(domain_start,domain_end)] = [domain_id]
						else :
							domain_dict[(domain_start,domain_end)].append(domain_id)

				align_ids = []
				align_boundaries_dict = {}
				with open("/home/nina/scripts/elm_in_ank/2014.12.01/NinaAlignments/conservation_identity_30/alignments_30identity/%s_blast.output_alignments_30identity.txt" % uniprot_id, 'rU') as file_open :
					data = file_open.readlines()
						
					for line in data : 
						line = line.split("	")

						if line[0][:5] == "query" :
							align_id = int(line[0][6:])

							if align_id <= 1000 :
								align_start = int(line[2])
								align_end = int(line[3])


								for (domain_start,domain_end) in domain_dict :
									domain_id = domain_dict[(domain_start,domain_end)]

									if (align_start <= domain_start) and (align_end >= domain_end) :
										align_ids.append(align_id)
										align_boundaries_dict[align_id] = (align_start, align_end)
										seq_query = (line[4].replace("
","")).replace("-","")
										file_write_query.write(">%s_%s	%s	%s
" % (uniprot_id, align_id, align_start, align_end))
										file_write_query.write("%s
" % seq_query)
										break
									else :
										continue								


					for line in data :
						line = line.split("	")

						if (line[0][:3] == "hit"): 
							align_id = int(line[0][4:])

							if align_id in align_ids :
								seq_hit = (line[4].replace("
","")).replace("-","")
								homolog_id = line[1]
								align_start = align_boundaries_dict[align_id][0]
								align_end = align_boundaries_dict[align_id][1]
								file_write_hit.write(">%s|%s_%s	%s	%s
" % (homolog_id, uniprot_id, align_id, align_start, align_end))
								file_write_hit.write("%s
" % seq_hit)






stop = timeit.default_timer()
print stop - start

make_fasta_BD.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
from Bio import SeqIO


my_fasta = sys.argv[1]
uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)


with open("check_pfam_in_%s" % my_fasta, 'a+') as file_write_query : 
	with open("check_pfam_in_%s_homolog_hits.fasta" % (my_fasta[:-6]), 'a+') as file_write_hit : 

		for uniprot_id in uniprot_list_total :

			domain_dict = {}
			filename = "pfam_in_%s/%s_pfam.txt" % (my_fasta[:-6], uniprot_id)
			if os.path.isfile(filename) == True :
				print uniprot_id

				with open(filename, 'rU') as file_open :
					data = file_open.readlines()
					for line in data :
						line = line.split("	")
						domain_start = int(line[1])
						domain_end = int(line[2])
						domain_id = line[5]
						if (domain_start, domain_end) not in domain_dict :
							domain_dict[(domain_start,domain_end)] = [domain_id]
						else :
							domain_dict[(domain_start,domain_end)].append(domain_id)

				align_ids = []
				align_boundaries_dict = {}
				with open("/home/nina/scripts/paper_elm_2014/elms/elm_conservation/elm_conservation_data/binding_partners/conservation_identity_30/alignments_30identity/%s_blast.output_alignments_30identity.txt" % uniprot_id, 'rU') as file_open :
					data = file_open.readlines()
						
					for line in data : 
						line = line.split("	")

						if line[0][:5] == "query" :
							align_id = int(line[0][6:])

							if align_id <= 1000 :
								align_start = int(line[2])
								align_end = int(line[3])


								for (domain_start,domain_end) in domain_dict :
									domain_id = domain_dict[(domain_start,domain_end)]

									if (align_start <= domain_start) and (align_end >= domain_end) :
										align_ids.append(align_id)
										align_boundaries_dict[align_id] = (align_start, align_end)
										seq_query = (line[4].replace("
","")).replace("-","")
										file_write_query.write(">%s_%s	%s	%s
" % (uniprot_id, align_id, align_start, align_end))
										file_write_query.write("%s
" % seq_query)
										break
									else :
										continue								


					for line in data :
						line = line.split("	")

						if (line[0][:3] == "hit"): 
							align_id = int(line[0][4:])

							if align_id in align_ids :
								seq_hit = (line[4].replace("
","")).replace("-","")
								homolog_id = line[1]
								align_start = align_boundaries_dict[align_id][0]
								align_end = align_boundaries_dict[align_id][1]
								file_write_hit.write(">%s|%s_%s	%s	%s
" % (homolog_id, uniprot_id, align_id, align_start, align_end))
								file_write_hit.write("%s
" % seq_hit)






stop = timeit.default_timer()
print stop - start

make_indep_fasta_BD_XXX.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
from Bio import SeqIO


my_fasta = sys.argv[1]

threshold = int(sys.argv[2])

uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)

cmd1 = "mkdir %s_MaxHomologs_%s_queries_fastas" % (my_fasta[:-6], threshold )
cmd2 = "mkdir %s_MaxHomologs_%s_homologs_fastas" % (my_fasta[:-6], threshold )
os.system(cmd1)
os.system(cmd2)


for uniprot_id in uniprot_list_total :

	domain_dict = {}
	filename = "pfam_in_%s/%s_pfam.txt" % (my_fasta[:-6], uniprot_id)
	
	if os.path.isfile(filename) == True :
		print uniprot_id

		with open("%s_MaxHomologs_%s_queries_fastas/check_pfam_in_%s_MaxHomologs_%s_query_seq.fasta" % (my_fasta[:-6], threshold, uniprot_id, threshold), 'a+') as file_write_query : 
			with open("%s_MaxHomologs_%s_homologs_fastas/check_pfam_in_%s_MaxHomologs_%s_homolog_hit_seq.fasta" % (my_fasta[:-6],threshold, uniprot_id, threshold), 'a+') as file_write_hit : 


				with open(filename, 'rU') as file_open :
					data = file_open.readlines()
					for line in data :
						line = line.split("	")
						domain_start = int(line[1])
						domain_end = int(line[2])
						domain_id = line[5]
						if (domain_start, domain_end) not in domain_dict :
							domain_dict[(domain_start,domain_end)] = [domain_id]
						else :
							domain_dict[(domain_start,domain_end)].append(domain_id)

				align_ids = []
				align_boundaries_dict = {}
				with open("/home/nina/scripts/paper_elm_2014/elms/elm_conservation/elm_conservation_data/binding_partners/conservation_identity_30/alignments_30identity/%s_blast.output_alignments_30identity.txt" % uniprot_id, 'rU') as file_open :
					data = file_open.readlines()
						
					for line in data : 
						line = line.split("	")

						if line[0][:5] == "query" :
							align_id = int(line[0][6:])

							if threshold-100 < align_id <= threshold :
								align_start = int(line[2])
								align_end = int(line[3])


								for (domain_start,domain_end) in domain_dict :
									domain_id = domain_dict[(domain_start,domain_end)]

									if (align_start <= domain_start) and (align_end >= domain_end) :
										align_ids.append(align_id)
										align_boundaries_dict[align_id] = (align_start, align_end)
										seq_query = (line[4].replace("
","")).replace("-","")
										file_write_query.write(">%s_%s	%s	%s
" % (uniprot_id, align_id, align_start, align_end))
										file_write_query.write("%s
" % seq_query)
										break
									else :
										continue								


					for line in data :
						line = line.split("	")

						if (line[0][:3] == "hit"): 
							align_id = int(line[0][4:])

							if align_id in align_ids :
								seq_hit = (line[4].replace("
","")).replace("-","")
								homolog_id = line[1]
								align_start = align_boundaries_dict[align_id][0]
								align_end = align_boundaries_dict[align_id][1]
								file_write_hit.write(">%s|%s_%s	%s	%s
" % (homolog_id, uniprot_id, align_id, align_start, align_end))
								file_write_hit.write("%s
" % seq_hit)






stop = timeit.default_timer()
print stop - start

make_multifasta.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

from Bio import SeqIO
import sys


# if sys.argv[1] == "non_ankregions" : declare large linker size threshold as sys.argv[2]
# if sys.argv[1] == "ankregions" : declare large linker size threshold as sys.argv[2]
# if sys.argv[1] == "ank_linkers" : declare large linker size threshold as sys.argv[2]
# if sys.argv[1] == "all_ank_linkers"
# if sys.argv[1] == "ank_repeats"
# if sys.argv[1] == "ank_proteins"

#declare fasta ank_proteins according to uniprot
#and build sequence_dict :
ank_proteins_from_uniprot_fasta = "all-ank-20130926.fasta"
sequence_dict = {}
uniprot_list_total = []
with open(ank_proteins_from_uniprot_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)
		uniprot_seq = str(record.seq)
		sequence_dict[uniprot_id] = uniprot_seq

#get the unp list of ank proteins for which rocio hmmer search detected repeats. (there are 1191)
ankyrin_list = [] 
with open("uniprot_hmmer1_results_for_all_ank_1238.txt", 'rU') as file_read :
	data = file_read.readlines()
	for line in data :	
		uniprot_id = line.replace("
","")
		ankyrin_list.append(uniprot_id) 



if sys.argv[1] == "ank_proteins" :
	#build fasta ank_proteins according to rocio's detection:
	with open(ank_proteins_from_uniprot_fasta, 'rU') as fasta_handle :
		with open("ankproteins_1191.fasta", 'a+') as file_write :
			for uniprot_id in ankyrin_list :
				sequence = sequence_dict[uniprot_id]
				file_write.write(">sp|%s|%s
" % (uniprot_id, len(sequence)))
				file_write.write("%s
" % sequence)


if sys.argv[1] == "ank_repeats" :
	#build fasta for repeats:
	with open("ankrepeats_1191.fasta", 'a+') as file_write :
		for uniprot_id in ankyrin_list :
			with open("/Users/verstrat/temp_qb/paper_elm_2014/ank_repeats_analysis/compute_ank1238/%s_compute_ank.txt" % uniprot_id, 'rU') as file_read :
				data = file_read.readlines()
				for i in range(0, len(data)) :
					data[i] = data[i].split("	")
					sequence_start = int(data[i][2])
					sequence_end = int(data[i][3])
					sequence = sequence_dict[uniprot_id][sequence_start-1:sequence_end]
					file_write.write(">sp|%s|%s|ank_repeat_%s|%s|%s|%s
" % (uniprot_id, len(sequence_dict[uniprot_id]), i+1, sequence_start, sequence_end, len(sequence)))
					file_write.write("%s
" % sequence)


if sys.argv[1] == "all_ank_linkers" :
	#build fasta for linkers (=between repeats OF ALL SIZES)):
	with open("anklinkers_1191.fasta", 'a+') as file_write :
		for uniprot_id in ankyrin_list :
			with open("/Users/verstrat/temp_qb/paper_elm_2014/ank_repeats_analysis/compute_linkers1191_correct/%s_anklinkers.txt" % uniprot_id, 'rU') as file_read :
				data = file_read.readlines()
				for i in range(0, len(data)) :
					data[i] = data[i].split("	")
					anklinker_length = int(data[i][4].replace("
",""))
					sequence_start = int(data[i][2])
					sequence_end = int(data[i][3])
					sequence = sequence_dict[uniprot_id][sequence_start-1:sequence_end]
					file_write.write(">sp|%s|%s|ank_linker_%s|%s|%s|%s
" % (uniprot_id, len(sequence_dict[uniprot_id]), i+1, sequence_start, sequence_end, len(sequence)))
					file_write.write("%s
" % sequence)


if sys.argv[1] == "ank_linkers" :
	threshold = int(sys.argv[2])
	#build fasta for linkers (=between repeats AND < 132aa)):
	with open("anklinkers_1191_threshold%s.fasta" % threshold, 'a+') as file_write :
		for uniprot_id in ankyrin_list :
			with open("/Users/verstrat/temp_qb/paper_elm_2014/ank_repeats_analysis/compute_linkers1191_correct/%s_anklinkers.txt" % uniprot_id, 'rU') as file_read :
				data = file_read.readlines()
				for i in range(0, len(data)) :
					data[i] = data[i].split("	")
					anklinker_length = int(data[i][4].replace("
",""))
					if anklinker_length < threshold :
						sequence_start = int(data[i][2])
						sequence_end = int(data[i][3])
						sequence = sequence_dict[uniprot_id][sequence_start-1:sequence_end]
						file_write.write(">sp|%s|%s|ank_linker_%s|%s|%s|%s
" % (uniprot_id, len(sequence_dict[uniprot_id]), i+1, sequence_start, sequence_end, len(sequence)))
						file_write.write("%s
" % sequence)

if sys.argv[1] == "ankregions" :
	threshold = int(sys.argv[2])
	#build fasta for regions:
	with open("ankregions_1191_threshold%s.fasta" % threshold, 'a+') as file_write :
		for uniprot_id in ankyrin_list :
			with open("/Users/verstrat/temp_qb/paper_elm_2014/ank_repeats_analysis/compute_ankregions1191_threshold%s/%s_ankregions.txt" % (threshold, uniprot_id), 'rU') as file_read :
				data = file_read.readlines()
				for i in range(0, len(data)) :
					data[i] = data[i].split("	")
					sequence_start = int(data[i][2])
					sequence_end = int(data[i][3])
					sequence = sequence_dict[uniprot_id][sequence_start-1:sequence_end]
					file_write.write(">sp|%s|%s|ankregion_%s|%s|%s|%s
" % (uniprot_id, len(sequence_dict[uniprot_id]), i+1, sequence_start, sequence_end, len(sequence)))
					file_write.write("%s
" % sequence)

if sys.argv[1] == "non_ankregions" :
	threshold = int(sys.argv[2])
	#build fasta for regions:
	with open("non_ankregions_1191_threshold%s.fasta" % threshold, 'a+') as file_write :
		for uniprot_id in ankyrin_list :
			with open("/Users/verstrat/temp_qb/paper_elm_2014/ank_repeats_analysis/compute_non_ankregions1191_threshold%s/%s_non_ankregions.txt" % (threshold,uniprot_id), 'rU') as file_read :
				data = file_read.readlines()
				for i in range(0, len(data)) :
					data[i] = data[i].split("	")
					sequence_start = int(data[i][2])
					sequence_end = int(data[i][3])
					sequence = sequence_dict[uniprot_id][sequence_start-1:sequence_end]
					file_write.write(">sp|%s|%s|non_ankregion_%s|%s|%s|%s
" % (uniprot_id, len(sequence_dict[uniprot_id]), i+1, sequence_start, sequence_end, len(sequence)))
					file_write.write("%s
" % sequence)


stop = timeit.default_timer()
print stop - start 

map_elm_to_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math


pfam_family_with_no_clan = []
pfam_family_list = []
pfam_clan_list = []
family_clan_mapping_dict = {}
family_clan_mapping_dict_update = {}
with open("Pfam-A.clans.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		pfam_family = line[0]
		pfam_family_list.append(pfam_family)
		pfam_clan = line[2]
		pfam_clan_ID = line[1]
		if pfam_clan != '\N' :
			pfam_clan_list.append(pfam_clan)
		if pfam_clan == '\N' :
			pfam_family_with_no_clan.append(pfam_family)
		family_clan_mapping_dict[pfam_family] = pfam_clan
		family_clan_mapping_dict_update[pfam_family] = pfam_clan_ID

print len(pfam_family_list)
print len(family_clan_mapping_dict)
# print family_clan_mapping_dict
print len(pfam_clan_list)
print len(set(pfam_clan_list))

print len(pfam_family_with_no_clan)

# with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
# 	data = file_open.readlines()
# 	with open("elm_interaction_clans.txt", 'a+') as file_write :
# 		file_write.write("%s	Pfam_clan
" % data[0].replace("
",""))
# 		for line in data[1:] :
# 			line = line.split("	")
# 			elm_name = line[0]
# 			pfam_family = line[1]
# 			pfam_clan = family_clan_mapping_dict[pfam_family]
# 			file_write.write("%s	%s	%s
" % ('	'.join(line[:-1]), line[-1].replace("
",""), pfam_clan))

with open("elm_interaction_domains_modified.txt", 'rU') as file_open :
	data = file_open.readlines()
	with open("elm_interaction_clans_update.txt", 'a+') as file_write :
		file_write.write("%s	Pfam_clan_ID
" % data[0].replace("
",""))
		for line in data[1:] :
			line = line.split("	")
			elm_name = line[0]
			pfam_family = line[1]
			pfam_clan_ID = family_clan_mapping_dict_update[pfam_family]
			file_write.write("%s	%s	%s
" % ('	'.join(line[:-1]), line[-1].replace("
",""), pfam_clan_ID))





stop = timeit.default_timer()
print stop - start 

parse_and_count_pfam_BD_bis.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
from Bio import SeqIO
import math


fasta_file_all_ank = sys.argv[1]
fasta_file_BD = sys.argv[2]


# build unp_list from fasta and extract the UNP_IDs correpsonding to ankyrin (from 1234)

unp_from_all_ank, unp_from_BD,  = [],[]
with open(fasta_file_all_ank, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		unp_id = record.id[3:9]
		unp_from_all_ank.append(unp_id) 

with open(fasta_file_BD, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		unp_id = record.id[3:9]
		unp_from_BD.append(unp_id) 

unp_from_BD_without_ank = []
for unp_id in unp_from_BD :
	if unp_id in unp_from_all_ank :
		pass
	else :
		unp_from_BD_without_ank.append(unp_id)

print len(unp_from_BD_without_ank) #2028 OK

#build dict of total swissprot counts for all PFAM domains
Pfam_count_dict, Pfam_description_dict = {},{}
total = 0
with open("FrequenciesPfam_mapped.txt", 'rU') as file_read :
	data = file_read.readlines()
	for line in data[1:] :
		line = line.split("	")
		domain = line[1]
		description = line[-2]
		domain_count_in_swissprot = (line[-1].replace("
",""))
		Pfam_count_dict[domain] = float(domain_count_in_swissprot)
		total = total + Pfam_count_dict[domain]
		Pfam_description_dict[domain] = description
print len(Pfam_count_dict) #14'831
print total #28738352.0

unp_list, domain_list, Pfam_type_list = [], [], []
with open("pfam_in_binding_partners_2038/CONCATEN.txt", 'rU') as file_open : 
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		unp_id = line[0]
		if unp_id in unp_from_BD_without_ank :
			unp_list.append(unp_id)
			domain_name = line[6]
			domain_list.append(domain_name)

		
print 'len(unp_list)', len(unp_list)
print "len(set(unp_list))",len(set(unp_list))
print 'len(domain_list)', len(domain_list)
print "len(set(domain_list))",len(set(domain_list))

count_domain_names = Counter(domain_list)
print len(count_domain_names)


num_prot_in_swissprot = 545388
num_prot_in_subfamily = 2038 #len(set(unp_list))
with open("%s_pfam_domains_counts_WITHOUT_ank_IDs_2038.txt" % fasta_file_BD[:-5], 'a+') as file_write :
	file_write.write("Domain name	# in Ank binding partners	# in Uniprot	expected # in Ank binding partners	log(obs/exp)
")
	for domain_name in count_domain_names :
		# if domain_name == 'DUF3424' :
		# 	pass
		# else :
		domain_count_in_subfamily = float(count_domain_names[domain_name])
		domain_count_in_unp = float(Pfam_count_dict[domain_name])
		exp_count_in_subfamily = float(domain_count_in_unp * num_prot_in_subfamily / num_prot_in_swissprot)
		obs_exp = domain_count_in_subfamily/exp_count_in_subfamily
		file_write.write("%s	%s	%s	%s	%s
" % (domain_name, domain_count_in_subfamily, domain_count_in_unp, exp_count_in_subfamily, math.log(obs_exp)))


# import glob
# for filename in glob.iglob("%s_pfam_domains_counts_without_ank_IDs.txt" % fasta_file_BD[:-5]) :
# 	print filename
# 	with open(filename, 'rU') as file_read :
# 		with open("%s_replaced.txt" % filename[:-4], 'a+') as file_write :
# 			data = file_read.readlines()
# 			for line in data :
# 				line = line.replace(".",",")
# 				file_write.write("%s" % line)




stop = timeit.default_timer()
print stop - start

parse_and_count_pfam_families_and_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
from collections import Counter
import re
import glob


pfam_file = sys.argv[1]


# unp_list, domain_list, clan_list = [], [], []

# for filename in glob.iglob("pfam_in_%s/*.txt" % pfam_file[:-6]) :
# 	print filename
# 	with open(filename, 'rU') as file_open :
# 		data = file_open.readlines()
# 		for line in data :
# 			line = line.split("	")
# 			domain_name = line[6]
# 			domain_list.append(domain_name)
# 			unp_id = line[0]
# 			unp_list.append(unp_id)
# 			clan_name = line[14].replace("
","")
# 			clan_list.append(clan_name)
		
# print 'len(unp_list)', len(unp_list)
# print "len(set(unp_list))",len(set(unp_list))
# print 'len(domain_list)', len(domain_list)
# print "len(set(domain_list))",len(set(domain_list))
# print 'len(clan_list)', len(clan_list)
# print "len(set(clan_list))",len(set(clan_list))


unp_list, domain_list, clan_list = [], [], []

for filename in glob.iglob("pfam_in_%s/*.txt" % pfam_file[:-6]) :
	print filename
	with open(filename, 'rU') as file_open :
		data = file_open.readlines()
		for line in data :
			line = line.split("	")
			clan_name = line[14].replace("
","")
			if clan_name != "No_clan" :
				clan_list.append(clan_name)
			else :
				domain_name = line[6]
				domain_list.append(domain_name)
			unp_id = line[0]
			unp_list.append(unp_id)

		
print 'len(unp_list)', len(unp_list)
print "len(set(unp_list))",len(set(unp_list))
print 'len(domain_list)', len(domain_list)
print "len(set(domain_list))",len(set(domain_list))
print 'len(clan_list)', len(clan_list)
print "len(set(clan_list))",len(set(clan_list))


count_domain_names = Counter(domain_list)

count_clan_names = Counter(clan_list)

count_domain_and_clan_names = dict(count_domain_names.items() + count_clan_names.items())


print len(count_domain_names)
print len(count_clan_names)
print len(count_domain_and_clan_names)





#build dict of total swissprot counts for all PFAM domains
Pfam_count_dict = {}
with open("FrequenciesPfam_mapped_CLANS.txt", 'rU') as file_read :
	data = file_read.readlines()
	for line in data :
		line = line.split("	")
		domain = line[0]
		domain_count_in_swissprot = (line[-1].replace("
",""))
		Pfam_count_dict[domain] = float(domain_count_in_swissprot)
print len(Pfam_count_dict) #10784







import math
num_prot_in_swissprot = 545388
num_prot_in_subfamily = len(set(unp_list))

with open("Pfam_clans_and_families_counts_in_%s.txt" % pfam_file[:-6], 'a+') as file_write :
	file_write.write("Domain/CLAN name	# in Ank binding partners	# in Uniprot	expected # in Ank binding partners	log(obs/exp)
")
	for domain_name in count_domain_and_clan_names :
		domain_count_in_subfamily = float(count_domain_and_clan_names[domain_name])
		domain_count_in_unp = float(Pfam_count_dict[domain_name])
		exp_count_in_subfamily = float(domain_count_in_unp * num_prot_in_subfamily / num_prot_in_swissprot)
		obs_exp = domain_count_in_subfamily/exp_count_in_subfamily
		file_write.write("%s	%s	%s	%s	%s
" % (domain_name, domain_count_in_subfamily, domain_count_in_unp, exp_count_in_subfamily, math.log(obs_exp)))


# import glob
# for filename in glob.iglob("%s_pfam_domains_counts.txt" % pfam_file[:-5]) :
# 	print filename
# 	with open(filename, 'rU') as file_read :
# 		with open("%s_replaced.txt" % filename[:-4], 'a+') as file_write :
# 			data = file_read.readlines()
# 			for line in data :
# 				line = line.replace(".",",")
# 				file_write.write("%s" % line)











stop = timeit.default_timer()
print stop - start

pfam_scan_BD_XXX.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
import re
from Bio import SeqIO
import subprocess


my_fasta = sys.argv[1]

threshold = int(sys.argv[2])

uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)


cmd1 = "mkdir %s_MaxHomologs_%s_queries_pfam_output" % (my_fasta[:-6], threshold)
cmd2 = "mkdir %s_MaxHomologs_%s_homologs_pfam_output" % (my_fasta[:-6], threshold)
os.system(cmd1)
os.system(cmd2)


for uniprot_id in uniprot_list_total :

	print uniprot_id
	sys.stdout.flush() # http://stackoverflow.com/questions/8537932/why-is-my-nohup-out-empty

	query_fasta = "%s_MaxHomologs_%s_queries_fastas/check_pfam_in_%s_MaxHomologs_%s_query_seq.fasta" % (my_fasta[:-6], threshold, uniprot_id, threshold)
	homolog_fasta = "%s_MaxHomologs_%s_homologs_fastas/check_pfam_in_%s_MaxHomologs_%s_homolog_hit_seq.fasta" % (my_fasta[:-6], threshold, uniprot_id, threshold)

	nohup_query_output = "%s_MaxHomologs_%s_queries_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_query.txt" % (my_fasta[:-6], threshold, uniprot_id, threshold)
	nohup_homolog_output = "%s_MaxHomologs_%s_homologs_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_homolog.txt" % (my_fasta[:-6], threshold, uniprot_id, threshold)

	cmd_query = "nohup perl pfam_scan.pl -fasta %s -dir /home/nina/scripts/domain_retrieve/Pfam_local_search/PfamScan &" % (query_fasta)
	# cmd_query = cmd_query.split(" ")

	cmd_homolog = "nohup perl pfam_scan.pl -fasta %s -dir /home/nina/scripts/domain_retrieve/Pfam_local_search/PfamScan &" % (homolog_fasta)
	# cmd_homolog = cmd_homolog.split(" ")
	
	pfam_scan_query_output = subprocess.Popen(cmd_query, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)
	stdoutdata_query = pfam_scan_query_output.communicate()[0]
	with open(nohup_query_output, 'a+') as file_write :
		file_write.write("%s" % stdoutdata_query)

	pfam_scan_homolog_output = subprocess.Popen(cmd_homolog, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)
	stdoutdata_homolog = pfam_scan_homolog_output.communicate()[0]
	with open(nohup_homolog_output, 'a+') as file_write :
		file_write.write("%s" % stdoutdata_homolog)






stop = timeit.default_timer()
print stop - start

pfam_scan_BD_tannat_XXX.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()

import sys
import os
import re
from Bio import SeqIO
import subprocess


my_fasta = sys.argv[1]

threshold = int(sys.argv[2])

uniprot_list_total = []
with open(my_fasta, 'rU') as fasta_handle :
	for record in SeqIO.parse(fasta_handle, "fasta") :
		uniprot_id = record.id[3:9]
		uniprot_list_total.append(uniprot_id)


cmd1 = "mkdir %s_MaxHomologs_%s_queries_pfam_output" % (my_fasta[:-6], threshold)
cmd2 = "mkdir %s_MaxHomologs_%s_homologs_pfam_output" % (my_fasta[:-6], threshold)
os.system(cmd1)
os.system(cmd2)


for uniprot_id in uniprot_list_total :

	print uniprot_id
	sys.stdout.flush() # http://stackoverflow.com/questions/8537932/why-is-my-nohup-out-empty

	query_fasta = "%s_MaxHomologs_%s_queries_fastas/check_pfam_in_%s_MaxHomologs_%s_query_seq.fasta" % (my_fasta[:-6], threshold, uniprot_id, threshold)
	homolog_fasta = "%s_MaxHomologs_%s_homologs_fastas/check_pfam_in_%s_MaxHomologs_%s_homolog_hit_seq.fasta" % (my_fasta[:-6], threshold, uniprot_id, threshold)

	nohup_query_output = "%s_MaxHomologs_%s_queries_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_query.txt" % (my_fasta[:-6], threshold, uniprot_id, threshold)
	nohup_homolog_output = "%s_MaxHomologs_%s_homologs_pfam_output/pfam_domains_in_%s_MaxHomologs_%s_homolog.txt" % (my_fasta[:-6], threshold, uniprot_id, threshold)

	cmd_query = "nohup perl pfam_scan.pl -cpu 4 -fasta %s -dir /home/tannat/Desktop/Nina/domain_retrieve/Pfam_local_search/PfamScan/binding_partners &" % (query_fasta)
	# cmd_query = cmd_query.split(" ")

	cmd_homolog = "nohup perl pfam_scan.pl -cpu 4 -fasta %s -dir /home/tannat/Desktop/Nina/domain_retrieve/Pfam_local_search/PfamScan/binding_partners &" % (homolog_fasta)
	# cmd_homolog = cmd_homolog.split(" ")
	
	pfam_scan_query_output = subprocess.Popen(cmd_query, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)
	stdoutdata_query = pfam_scan_query_output.communicate()[0]
	with open(nohup_query_output, 'a+') as file_write :
		file_write.write("%s" % stdoutdata_query)

	pfam_scan_homolog_output = subprocess.Popen(cmd_homolog, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)
	stdoutdata_homolog = pfam_scan_homolog_output.communicate()[0]
	with open(nohup_homolog_output, 'a+') as file_write :
		file_write.write("%s" % stdoutdata_homolog)






stop = timeit.default_timer()
print stop - start

rebuild_domains_enrichment.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math

elm_domain_and_clan_mapping_dict = {}
domain_and_clan_elm_mapping_dict = {}

with open("elm_interaction_clans_update.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		elm_name = line[0]
		if line[-1] == '\N
' : 
			domain_or_clan = line[2]
		else : 
			domain_or_clan = line[-1].replace("
","")

		if elm_name not in elm_domain_and_clan_mapping_dict :
			elm_domain_and_clan_mapping_dict[elm_name] = [domain_or_clan]
		else :
			elm_domain_and_clan_mapping_dict[elm_name].append(domain_or_clan)

		if domain_or_clan not in domain_and_clan_elm_mapping_dict :
			domain_and_clan_elm_mapping_dict[domain_or_clan] = [elm_name]
		else :
			domain_and_clan_elm_mapping_dict[domain_or_clan].append(elm_name)

print len(domain_and_clan_elm_mapping_dict), len(elm_domain_and_clan_mapping_dict)

# for i in domain_and_clan_elm_mapping_dict :
# 	print i, domain_and_clan_elm_mapping_dict[i]

# print domain_and_clan_elm_mapping_dict["CL0020"]

# with open("domains_clans_to_elms_mapping.txt", 'a+') as file_write :
# 	for i in domain_and_clan_elm_mapping_dict :
# 		print i, domain_and_clan_elm_mapping_dict[i]
# 		for j in range(0, len(domain_and_clan_elm_mapping_dict[i])) :
# 			file_write.write("%s	%s
" % (i, domain_and_clan_elm_mapping_dict[i][j]))

# with open("elms_to_domains_clans_mapping.txt", 'a+') as file_write :
# 	for i in elm_domain_and_clan_mapping_dict :
# 		print i, elm_domain_and_clan_mapping_dict[i]
# 		for j in range(0, len(elm_domain_and_clan_mapping_dict[i])) :
# 			file_write.write("%s	%s
" % (i, elm_domain_and_clan_mapping_dict[i][j]))


# filename = sys.argv[1]

# with open("counts/%s_binding_MAPPED.txt" % filename[:-4], 'a+') as file_write :
# 	with open("counts/%s" % filename, 'rU') as file_open :
# 		data = file_open.readlines()
# 		first_line_splitted = data[0].split("	")
# 		file_write.write("%s	binding_domain_or_clan	%s" % (first_line_splitted[0], '	'.join(first_line_splitted[1:])))
# 		for line in data[1:] :
# 			line = line.split("	")
# 			elm_name = line[0]
# 			if elm_name in elm_domain_and_clan_mapping_dict :
# 				if len(elm_domain_and_clan_mapping_dict[elm_name]) == 1 :
# 					binding_domain_or_clan = elm_domain_and_clan_mapping_dict[elm_name][0]
# 				else :
# 					binding_domain_or_clan = ', '.join(elm_domain_and_clan_mapping_dict[elm_name])
# 				print elm_name, binding_domain_or_clan
# 				file_write.write("%s	%s	%s" % (elm_name, binding_domain_or_clan, '	'.join(line[1:])))
# 			else :
# 				print elm_name, "no binding domain or clan"
# 				file_write.write("%s	%s	%s" % (elm_name, "NULL", '	'.join(line[1:])))



# filename = sys.argv[1]

# with open("counts/%s_binding_MAPPED.txt" % filename[:-4], 'a+') as file_write :
# 	with open("counts/%s" % filename, 'rU') as file_open :
# 		data = file_open.readlines()
# 		first_line_splitted = data[0].split("	")
# 		file_write.write("%s	%s	binding_elm	%s" % ("domain", "domain_or_clan", '	'.join(first_line_splitted[2:])))
# 		for line in data[1:] :
# 			line = line.split("	")
# 			clan_name = line[1]
# 			domain_name = line[0]
# 			if clan_name == 'NULL' :
# 				domain_or_clan_name = line[0]
# 			else : 
# 				domain_or_clan_name = line[1]

# 			if domain_or_clan_name in domain_and_clan_elm_mapping_dict :
# 				if len(domain_and_clan_elm_mapping_dict[domain_or_clan_name]) == 1 :
# 					binding_elm = domain_and_clan_elm_mapping_dict[domain_or_clan_name][0]
# 				else :
# 					binding_elm = ', '.join(domain_and_clan_elm_mapping_dict[domain_or_clan_name])


# 				file_write.write("%s	%s	%s	%s" % (domain_name, domain_or_clan_name, binding_elm, '	'.join(line[2:])))

# 			else :
# 				#print domain_name, "no binding elm"
# 				file_write.write("%s	%s	%s	%s" % (domain_name, domain_or_clan_name, "NULL", '	'.join(line[2:])))








stop = timeit.default_timer()
print stop - start 

rename_domains_to_clans.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
# from Bio import SeqIO # to parse the fasta file
import collections
import math

family_clan_mapping_dict = {}

with open("Pfam-A.clans.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data[1:] :
		line = line.split("	")
		family = line[3]
		clan = line[1]
		if clan != "\N" :
			family_clan_mapping_dict[family] = clan
# print family_clan_mapping_dict


filename = sys.argv[1]
with open("%s_with_clans.txt" % filename[:-4], 'a+') as file_write :
	with open(filename, 'rU') as file_open :
		data = file_open.readlines()
		first_line_splitted = data[0].split("	")
		file_write.write("%s	CLAN	%s" % (first_line_splitted[0], '	'.join(first_line_splitted[1:])))		
		for line in data[1:] :
			line = line.split("	")
			domain_name = line[0]
			if domain_name in family_clan_mapping_dict :
				clan_name = family_clan_mapping_dict[domain_name]
			else :
				clan_name = "NULL"
			file_write.write("%s	%s	%s" % (domain_name, clan_name, '	'.join(line[1:])))






stop = timeit.default_timer()
print stop - start 

reorder_interacting_pairs_list.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re
from commands import getoutput # permet d'obtenir l'output d'une commande bash.
from numpy import prod
from Bio import SeqIO # to parse the fasta file
import collections
import math

ank_list = []
with open("mapping_table_unp_string_uniref50_UPPERCASE.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		ank_id = line[1].replace("
", "")
		ank_list.append(ank_id)

print len(ank_list),  len(set(ank_list))



with open("interacting_pairs_list.txt", 'rU') as file_open :
	data = file_open.readlines()
	with open("interacting_pairs_list_REORDED.txt", 'a+') as file_write :
		for line in data :
			partnerA = line[0:6]
			partnerB = line[7:].replace("
","")
			if partnerA in ank_list : #couvre le cas ou A=ank/B=bd et le cas ou A=ank/B=ank
				interacting_pair = "%s_%s" % (partnerA,partnerB)
			elif partnerA not in ank_list : #couvre les cas ou A=bd/B=ank
				interacting_pair = "%s_%s" % (partnerB,partnerA)
			else :
				print "wat"
			
			file_write.write("%s
" % interacting_pair)				

sort_elms.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-

import timeit
start = timeit.default_timer()
import sys
import os
import glob
import re

elm_list = []

top_elms_counts_in_ank_proteins, top_elms_counts_in_ankregions, top_elms_counts_in_non_ankregions, top_elms_counts_in_ank_repeats, top_elms_counts_in_ank_linkers = [], [], [], [], []

with open("top_elms_counts_in_ank_proteins_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		elm_list.append(elm_name)
		top_elms_counts_in_ank_proteins.append(elm_name)


with open("top_elms_counts_in_ankregions_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		elm_list.append(elm_name)
		top_elms_counts_in_ankregions.append(elm_name)

with open("top_elms_counts_in_non_ankregions_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		elm_list.append(elm_name)
		top_elms_counts_in_non_ankregions.append(elm_name)

with open("top_elms_counts_in_ank_repeats_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		elm_list.append(elm_name)
		top_elms_counts_in_ank_repeats.append(elm_name)


with open("top_elms_counts_in_ank_linkers_with_conservation_Zscores_colored.txt", 'rU') as file_open :
	data = file_open.readlines()
	for line in data :
		line = line.split("	")
		elm_name = line[0]
		elm_list.append(elm_name)
		top_elms_counts_in_ank_linkers.append(elm_name)


elm_list = list(set(elm_list))

print len(elm_list)
for elm_name in elm_list :
	print elm_name
	if elm_name in top_elms_counts_in_ank_proteins :
		print "ank proteins"
	if elm_name in top_elms_counts_in_ankregions :
		print "ank regions"
	if elm_name in top_elms_counts_in_non_ankregions :
		print "non ank regions"
	if elm_name in top_elms_counts_in_ank_repeats :
		print "ank repeats"
	if elm_name in top_elms_counts_in_ank_linkers :
		print "ank linkers"
	print "
"



stop = timeit.default_timer()
print stop - start 
