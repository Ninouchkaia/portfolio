{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50df80c4",
   "metadata": {},
   "source": [
    "# Pipeline de nettoyage & analyse — version professionnelle\n",
    "\n",
    "Ce notebook contient :\n",
    "- une **architecture modulaire** basée sur des fonctions réutilisables\n",
    "- un **bloc `main()`** pour exécuter les étapes souhaitées\n",
    "- un **contrôle global `VERBOSE`** (vprint) pour réactiver tous les `print()` historiques\n",
    "- un **schéma de workflow** (Mermaid) à visualiser\n",
    "\n",
    "\n",
    "**Remplace `xxxxxxxxx` par ton chemin local si tu veux enregistrer ou charger depuis un dossier spécifique.**\n",
    "\n",
    "\n",
    "> Utilise les cellules de code ci-dessous pour t'adapter ou exécuter étapes par étapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d419aa03",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "  A[Chargement CSVs] --> B[Construction du graphe NetworkX]\n",
    "  B --> C[Ajout attributs nodes]\n",
    "  C --> D[Extraction : nœuds Drug]\n",
    "  D --> E[Parsing: 'AND', ';', parenthèses]\n",
    "  E --> F[Merging & dédoublonnage]\n",
    "  F --> G[Comparaison avec drugs_used.csv]\n",
    "  G --> H[Export / Visualisations]\n",
    "```\n",
    "\n",
    "*Si ton environnement Jupyter n'affiche pas Mermaid, ce diagramme fournit la logique séquentielle à suivre.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals & vprint\n",
    "VERBOSE = True  # mettre False pour couper tous les vprints\n",
    "\n",
    "def vprint(msg):\n",
    "    if VERBOSE:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ddc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders\n",
    "import csv\n",
    "\n",
    "def load_nodes(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        nodes = [r for r in reader][1:]\n",
    "    node_names = [n[0] for n in nodes]\n",
    "    vprint(f\"Loaded {len(node_names)} nodes from {path}\")\n",
    "    return nodes, node_names\n",
    "\n",
    "def load_edges(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        edges = [tuple(r) for r in reader][1:]\n",
    "    vprint(f\"Loaded {len(edges)} edges from {path}\")\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph builder\n",
    "import networkx as nx\n",
    "\n",
    "def build_graph(node_names, nodes, edges):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(node_names)\n",
    "    G.add_edges_from(edges)\n",
    "    type_dict = {n[0]: n[1] for n in nodes}\n",
    "    descr_dict = {n[0]: n[2] for n in nodes}\n",
    "    nx.set_node_attributes(G, type_dict, 'type')\n",
    "    nx.set_node_attributes(G, descr_dict, 'description')\n",
    "    vprint('Graph built: nodes={}, edges={}'.format(G.number_of_nodes(), G.number_of_edges()))\n",
    "    return G, descr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug parsing utilities\n",
    "import re\n",
    "\n",
    "def extract_drugs(descr_dict):\n",
    "    drug_list = [k for k,v in descr_dict.items() if v.upper()=='DRUG']\n",
    "    vprint(f\"Extracted {len(drug_list)} drug nodes\")\n",
    "    return drug_list\n",
    "\n",
    "def parse_and(drug_list):\n",
    "    parsed = []\n",
    "    for d in drug_list:\n",
    "        if ' AND ' in d:\n",
    "            parsed.extend([x.strip() for x in d.split(' AND ')])\n",
    "        parsed.append(d.strip())\n",
    "    return list(dict.fromkeys(parsed))\n",
    "\n",
    "def parse_semicolon(drug_list):\n",
    "    parsed = []\n",
    "    for d in drug_list:\n",
    "        if '; ' in d:\n",
    "            parsed.extend([x.strip() for x in d.split('; ')])\n",
    "        parsed.append(d.strip())\n",
    "    return list(dict.fromkeys(parsed))\n",
    "\n",
    "def remove_parentheses(drug_list):\n",
    "    cleaned = []\n",
    "    for d in drug_list:\n",
    "        if re.search(r'\\s\\([^()]*\\)', d):\n",
    "            cleaned.append(re.sub(r'\\s\\([^()]*\\)', '', d))\n",
    "    return list(dict.fromkeys(cleaned))\n",
    "\n",
    "def merge_unique(*lists):\n",
    "    merged = []\n",
    "    for L in lists:\n",
    "        merged.extend(L)\n",
    "    return list(dict.fromkeys(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse drugs used in trials\n",
    "def parse_drugs_in_trials(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = [ln.strip().upper() for ln in f if ln.strip()]\n",
    "    parsed = []\n",
    "    for ln in lines:\n",
    "        parsed.extend(ln.split(' '))\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5faafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline example\n",
    "import time\n",
    "def run_pipeline(node_file='COVID19_GDDS_nodes.csv',\n",
    "                 edge_file='COVID19_GDDS_edges.csv',\n",
    "                 trials_file='drugs_used.csv',\n",
    "                 verbose=True):\n",
    "    global VERBOSE\n",
    "    VERBOSE = verbose\n",
    "    t0 = time.time()\n",
    "    nodes, node_names = load_nodes(node_file)\n",
    "    edges = load_edges(edge_file)\n",
    "    G, descr = build_graph(node_names, nodes, edges)\n",
    "    drugs = extract_drugs(descr)\n",
    "    p_and = parse_and(drugs)\n",
    "    p_sc = parse_semicolon(drugs)\n",
    "    merged = merge_unique(drugs, p_and, p_sc)\n",
    "    no_par = remove_parentheses(merged)\n",
    "    final = merge_unique(merged, no_par)\n",
    "    trials = parse_drugs_in_trials(trials_file)\n",
    "    vprint(f'Summary: initial drugs={len(drugs)}, parsed_and={len(p_and)}, parsed_semicolon={len(p_sc)}, final={len(final)}, trials_parsed={len(trials)}')\n",
    "    # small check\n",
    "    found_camostat = [d for d in final if 'CAMOSTAT' in d.upper()]\n",
    "    if found_camostat:\n",
    "        vprint('Camostat hits: ' + ', '.join(found_camostat))\n",
    "    t1 = time.time()\n",
    "    vprint(f'Elapsed: {t1-t0:.2f} s')\n",
    "    return {\n",
    "        'G': G, 'descr': descr, 'drugs': drugs,\n",
    "        'parsed_and': p_and, 'parsed_semicolon': p_sc,\n",
    "        'merged': merged, 'no_parentheses': no_par,\n",
    "        'final': final, 'trials_parsed': trials\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae49cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "# Remplace les chemins par les tiens si nécessaire (ou mets xxxxxxxxx devant)\n",
    "res = run_pipeline(node_file='COVID19_GDDS_nodes.csv',\n",
    "                   edge_file='COVID19_GDDS_edges.csv',\n",
    "                   trials_file='drugs_used.csv',\n",
    "                   verbose=True)\n",
    "\n",
    "# Exporte la liste finale dans un CSV\n",
    "import csv\n",
    "with open('/mnt/data/final_drug_list.csv', 'w', encoding='utf-8') as out:\n",
    "    w = csv.writer(out)\n",
    "    for d in res['final']:\n",
    "        w.writerow([d])\n",
    "vprint('final_drug_list.csv written to /mnt/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67fa45",
   "metadata": {},
   "source": [
    "## Conseils d'utilisation\n",
    "\n",
    "- Pour exécuter pas à pas : exécute cellule par cellule.\n",
    "- Pour exécuter le pipeline complet : exécute la cellule `Usage example`.\n",
    "- Si tu veux stocker ailleurs, remplace `/mnt/data/` par `xxxxxxxxx/ton_dossier`.\n",
    "- Si ton Jupyter n'affiche pas Mermaid, tu peux installer une extension (ex: jupyterlab-mermaid) ou copier le diagramme dans un rendu Mermaid en ligne.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
