#!/usr/bin/python
# -*- coding: utf-8 -*-

#update from version4
# we cumulated first and second version of the mapping tables. first versions were generated with the id mapping tool from uniprot website
# second versions were generated from a mapping given by pax-db website

#update from version2
# we avoid to open twice the fasta file and find the matched uniprot id only once
# in order to reach the end of the script more rapidly (originally it took 1350 seconds for the 17 datasets > with this script : 1130 seconds)

#description of the original version
# this script reads a fasta file of proteins and counts the amino acid occurences in each protein. Worth noticing is that it can happen that the length of some proteins vary from the sum of counted amino-acids.
# This is because in some sequence, there are ambiguities (ambiguous position (B,Z or X) see protparam expasy)
# this script also reads a dataset of protein abundance data. The abundance datasets are mainly composed of 2 columns : string ID - abundance score
# this script matches the string IDs to uniprot IDs through the use of a mapping file generated with the id mapping tool from uniprot.org and a mapping table given by pax-db website.



import timeit
start = timeit.default_timer()
import os
import sys
import re
from Bio import SeqIO # to parse the fasta file
from Bio import SeqUtils # Miscellaneous functions for dealing with sequences.
from Bio.SeqUtils import  ProtParam

# the list of the 17 datasets to be analyzed
# list of datasets that DO NOT require \n after ending a line (see end of the loop "for record in SeqIO.parse")
species_list = ["10090-M.musculus", "160490-S.pyogenes", "267671-L.interrogans", "3702-A.thaliana", "449447-M.aeruginosa", "4896-S.pombe", "4932-S.cerevisiae", "511145-E.coli", "6239-C.elegans", "7227-D.melanogaster", "83332-M.tuberculosis", "9606-H.sapiens", "9913-B.taurus"]
# list of datasets that require \n after ending a line (see end of the loop "for record in SeqIO.parse")
#species_list = ["224308-Spectral_counting_B.subtili", "593117-Spectral_counting_T.gammatolerans", "9031-Spectral_counting_G.gallus", "99287-Spectral_counting_S.typhimurium"]


for species in species_list:
	print species

	## we start by creating a list of uniprot ids that were mapped to string ids, from text files located in the folder mapping_tables 
	handle_mapping_table = open("/home/nina/scripts/paxdb/abundance_datasets/uniprot_id/%s_dataset.txt_uniprot_id" % species, "rU")
	read_mapping_table = handle_mapping_table.readlines()
	handle_fasta = open("/home/nina/scripts/paxdb/abundance_datasets/fasta_files/%s.fasta" % species, "rU") #opens the fasta file containing the sequences and their information
	handle_dataset = open("/home/nina/scripts/paxdb/abundance_datasets/datasets/%s_dataset.txt" % species, "rU") #opens the abundance dataset
	read_dataset = handle_dataset.readlines()
	abundance_dict = {}
	tot_a = 0
	tot_c = 0
	tot_d = 0
	tot_e = 0
	tot_f = 0
	tot_g = 0
	tot_h = 0
	tot_i = 0
	tot_k = 0
	tot_l = 0
	tot_m = 0
	tot_n = 0
	tot_p = 0
	tot_q = 0
	tot_r = 0
	tot_s = 0
	tot_t = 0
	tot_v = 0
	tot_w = 0
	tot_y = 0
	
	totweight_a = 0
	totweight_c = 0
	totweight_d = 0
	totweight_e = 0
	totweight_f = 0
	totweight_g = 0
	totweight_h = 0
	totweight_i = 0
	totweight_k = 0
	totweight_l = 0
	totweight_m = 0
	totweight_n = 0
	totweight_p = 0
	totweight_q = 0
	totweight_r = 0
	totweight_s = 0
	totweight_t = 0
	totweight_v = 0
	totweight_w = 0
	totweight_y = 0
	
	file_write = open("/home/nina/scripts/paxdb/abundance_datasets/tables/%s_table.txt" % species,'a+') 
	
	#print the keys of the dict (the amino acids) in the alphabetical order
	file_write.write("\t\t") # leaves space for "uniprot_id" and "string_id" columns
	# we will fill the columns one by one instead of using a loop, because the dictionary generated by the protparam tool is not sorted alphabetically
	file_write.write("A\t")
	file_write.write("C\t")
	file_write.write("D\t")
	file_write.write("E\t")
	file_write.write("F\t")
	file_write.write("G\t")
	file_write.write("H\t")
	file_write.write("I\t")
	file_write.write("K\t")
	file_write.write("L\t")
	file_write.write("M\t")
	file_write.write("N\t")
	file_write.write("P\t")
	file_write.write("Q\t")
	file_write.write("R\t")
	file_write.write("S\t")
	file_write.write("T\t")
	file_write.write("V\t")
	file_write.write("W\t")
	file_write.write("Y\t")
	file_write.write("all amino-acids\n") # this column will be used to fill in the total counts of amino acids
	

	file_write.write("uniprot_id\t") 
	file_write.write("string_id\t")
	file_write.write("\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t") # leaves 21 cases/columns empty (each amino-acid + all amino-acids case/column)
	file_write.write("abundance\n")
	
	for record in SeqIO.parse(handle_fasta, "fasta") : # for each uniprot in the fasta file : (for another obscur reason, the 2 for loops have to go in this order)
		for mapping in read_mapping_table :
			mapping = mapping.replace('\n', '') # remove '\n' only
			mapping = mapping.split("\t")
			if record.id[3:9] == mapping[1][0:6] : # matching uniprot id : if the uniprot id from the fasta file and the mapping file is identical
				for abundance_data in read_dataset :
					abundance_data = abundance_data.split("\t")
					if mapping[0] == abundance_data[1]: # matching string id : if the string id from the mapping file and the abundance file is identical
						my_seq = record.seq #get each sequence as a string
						X = ProtParam.ProteinAnalysis("%s" % my_seq)  # creates the variable containing the sequence, to be passed in the count_amino_acids function.
						dict_seq = X.count_amino_acids() # count the occurence of amino acid in each sequence and return as a dict
						#len_seq = len(my_seq)

						#print the list of proteins (containing uniprot id) in the first column
						file_write.write("%s\t" % record.id ) 
						
						#print the list of proteins as string id in the second column
						file_write.write("%s\t" % abundance_data[1] ) 
						
						#store the cumulated sums of each amino-acids
						tot_a = tot_a + float(dict_seq["A"])
						tot_c = tot_c + float(dict_seq["C"])
						tot_d = tot_d + float(dict_seq["D"])
						tot_e = tot_e + float(dict_seq["E"])
						tot_f = tot_f + float(dict_seq["F"])
						tot_g = tot_g + float(dict_seq["G"])
						tot_h = tot_h + float(dict_seq["H"])
						tot_i = tot_i + float(dict_seq["I"])
						tot_k = tot_k + float(dict_seq["K"])
						tot_l = tot_l + float(dict_seq["L"])
						tot_m = tot_m + float(dict_seq["M"])
						tot_n = tot_n + float(dict_seq["N"])
						tot_p = tot_p + float(dict_seq["P"])
						tot_q = tot_q + float(dict_seq["Q"])
						tot_r = tot_r + float(dict_seq["R"])
						tot_s = tot_s + float(dict_seq["S"])
						tot_t = tot_t + float(dict_seq["T"])
						tot_v = tot_v + float(dict_seq["V"])
						tot_w = tot_w + float(dict_seq["W"])
						tot_y = tot_y + float(dict_seq["Y"])

						#store the cumulated sums ponderated by the abundance values
						totweight_a = totweight_a + float(dict_seq["A"]) * float(abundance_data[2])
						totweight_c = totweight_c + float(dict_seq["C"]) * float(abundance_data[2])
						totweight_d = totweight_d + float(dict_seq["D"]) * float(abundance_data[2])
						totweight_e = totweight_e + float(dict_seq["E"]) * float(abundance_data[2])
						totweight_f = totweight_f + float(dict_seq["F"]) * float(abundance_data[2])
						totweight_g = totweight_g + float(dict_seq["G"]) * float(abundance_data[2])
						totweight_h = totweight_h + float(dict_seq["H"]) * float(abundance_data[2])
						totweight_i = totweight_i + float(dict_seq["I"]) * float(abundance_data[2])
						totweight_k = totweight_k + float(dict_seq["K"]) * float(abundance_data[2])
						totweight_l = totweight_l + float(dict_seq["L"]) * float(abundance_data[2])
						totweight_m = totweight_m + float(dict_seq["M"]) * float(abundance_data[2])
						totweight_n = totweight_n + float(dict_seq["N"]) * float(abundance_data[2])
						totweight_p = totweight_p + float(dict_seq["P"]) * float(abundance_data[2])
						totweight_q = totweight_q + float(dict_seq["Q"]) * float(abundance_data[2])
						totweight_r = totweight_r + float(dict_seq["R"]) * float(abundance_data[2])
						totweight_s = totweight_s + float(dict_seq["S"]) * float(abundance_data[2])
						totweight_t = totweight_t + float(dict_seq["T"]) * float(abundance_data[2])
						totweight_v = totweight_v + float(dict_seq["V"]) * float(abundance_data[2])
						totweight_w = totweight_w + float(dict_seq["W"]) * float(abundance_data[2])
						totweight_y = totweight_y + float(dict_seq["Y"]) * float(abundance_data[2])
						
						#print the counts of each amino acid of each protein as a table
						tot_amino_acid_per_protein = float(dict_seq["A"]) + float(dict_seq["C"]) + float(dict_seq["D"]) + float(dict_seq["E"]) + float(dict_seq["F"]) + float(dict_seq["G"]) + float(dict_seq["H"]) + float(dict_seq["I"]) + float(dict_seq["K"]) + float(dict_seq["L"]) + float(dict_seq["M"]) + float(dict_seq["N"]) + float(dict_seq["P"]) + float(dict_seq["Q"]) + float(dict_seq["R"]) + float(dict_seq["S"]) + float(dict_seq["T"]) + float(dict_seq["V"]) + float(dict_seq["W"]) + float(dict_seq["Y"])
						# this tot_amino_acid_per_protein is to fill the last column. We could have used len_seq but since it can differ from tot_amino_acid_per_protein, it has been seen with nacho that we would use the total count instead of sequence length.
						file_write.write("%f\t" % float(dict_seq["A"]))
						file_write.write("%f\t" % float(dict_seq["C"]))
						file_write.write("%f\t" % float(dict_seq["D"]))
						file_write.write("%f\t" % float(dict_seq["E"]))
						file_write.write("%f\t" % float(dict_seq["F"]))
						file_write.write("%f\t" % float(dict_seq["G"]))
						file_write.write("%f\t" % float(dict_seq["H"]))
						file_write.write("%f\t" % float(dict_seq["I"]))
						file_write.write("%f\t" % float(dict_seq["K"]))
						file_write.write("%f\t" % float(dict_seq["L"]))
						file_write.write("%f\t" % float(dict_seq["M"]))
						file_write.write("%f\t" % float(dict_seq["N"]))
						file_write.write("%f\t" % float(dict_seq["P"]))
						file_write.write("%f\t" % float(dict_seq["Q"]))
						file_write.write("%f\t" % float(dict_seq["R"]))
						file_write.write("%f\t" % float(dict_seq["S"]))
						file_write.write("%f\t" % float(dict_seq["T"]))
						file_write.write("%f\t" % float(dict_seq["V"]))
						file_write.write("%f\t" % float(dict_seq["W"]))
						file_write.write("%f\t" % float(dict_seq["Y"]))
						file_write.write("%f\t" % float(tot_amino_acid_per_protein))
			
						#print the abundance values for each protein as a column 
						file_write.write("%s" % (abundance_data[2]))
						#file_write.write("%s\n" % (abundance_data[2])) # for some datasets we have to jump a line otherwise things get written one a single line

	
	totweight_amino_acid = totweight_a + totweight_c + totweight_d + totweight_e + totweight_f + totweight_g + totweight_h + totweight_i + totweight_k + totweight_l + totweight_m + totweight_n + totweight_p + totweight_q + totweight_r + totweight_s + totweight_t + totweight_v + totweight_w + totweight_y
	tot_amino_acid = tot_a + tot_c + tot_d + tot_e + tot_f + tot_g + tot_h + tot_i + tot_k + tot_l + tot_m + tot_n + tot_p + tot_q + tot_r + tot_s + tot_t + tot_v + tot_w + tot_y
	
	file_write.write("\tTotal\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\n" % (tot_a, tot_c, tot_d, tot_e, tot_f, tot_g, tot_h, tot_i, tot_k, tot_l, tot_m, tot_n, tot_p, tot_q, tot_r, tot_s, tot_t, tot_v, tot_w, tot_y, tot_amino_acid))
	file_write.write("\tFraction\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\n" % (tot_a/tot_amino_acid, tot_c/tot_amino_acid, tot_d/tot_amino_acid, tot_e/tot_amino_acid, tot_f/tot_amino_acid, tot_g/tot_amino_acid, tot_h/tot_amino_acid, tot_i/tot_amino_acid, tot_k/tot_amino_acid, tot_l/tot_amino_acid, tot_m/tot_amino_acid, tot_n/tot_amino_acid, tot_p/tot_amino_acid, tot_q/tot_amino_acid, tot_r/tot_amino_acid, tot_s/tot_amino_acid, tot_t/tot_amino_acid, tot_v/tot_amino_acid, tot_w/tot_amino_acid, tot_y/tot_amino_acid, tot_amino_acid/tot_amino_acid))
	file_write.write("\tTotal weighted per abundance\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\n" % (totweight_a, totweight_c, totweight_d, totweight_e, totweight_f, totweight_g, totweight_h, totweight_i, totweight_k, totweight_l, totweight_m, totweight_n, totweight_p, totweight_q, totweight_r, totweight_s, totweight_t, totweight_v, totweight_w, totweight_y, totweight_amino_acid))
	file_write.write("\tFraction weighted per abundance\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%f\n" % (totweight_a/totweight_amino_acid, totweight_c/totweight_amino_acid, totweight_d/totweight_amino_acid, totweight_e/totweight_amino_acid, totweight_f/totweight_amino_acid, totweight_g/totweight_amino_acid, totweight_h/totweight_amino_acid, totweight_i/totweight_amino_acid, totweight_k/totweight_amino_acid, totweight_l/totweight_amino_acid, totweight_m/totweight_amino_acid, totweight_n/totweight_amino_acid, totweight_p/totweight_amino_acid, totweight_q/totweight_amino_acid, totweight_r/totweight_amino_acid, totweight_s/totweight_amino_acid, totweight_t/totweight_amino_acid, totweight_v/totweight_amino_acid, totweight_w/totweight_amino_acid, totweight_y/totweight_amino_acid, totweight_amino_acid/totweight_amino_acid))
	
	
	handle_mapping_table.close()				  
	handle_fasta.close()
	handle_dataset.close()
	


stop = timeit.default_timer()
print stop - start 